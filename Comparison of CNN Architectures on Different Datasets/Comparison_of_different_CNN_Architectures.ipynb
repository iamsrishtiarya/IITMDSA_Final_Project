{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNpF/lyOrUqWfsnJAMDbNcn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mariyaben/Comparison_of_different_CNN_Architectures/blob/main/Comparison_of_different_CNN_Architectures.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LeNet5 on MNIST Dataset"
      ],
      "metadata": {
        "id": "KSDgnFH5a0vE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "dB3ceruSaXRC",
        "outputId": "1fc93654-16f8-449b-d843-e28ff77ed0fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 2s 0us/step\n",
            "Epoch 1/10\n",
            "375/375 [==============================] - 8s 8ms/step - loss: 0.4548 - accuracy: 0.8639 - val_loss: 0.1538 - val_accuracy: 0.9546\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1308 - accuracy: 0.9598 - val_loss: 0.1076 - val_accuracy: 0.9668\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0890 - accuracy: 0.9723 - val_loss: 0.0801 - val_accuracy: 0.9768\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0673 - accuracy: 0.9796 - val_loss: 0.0625 - val_accuracy: 0.9816\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0546 - accuracy: 0.9827 - val_loss: 0.0538 - val_accuracy: 0.9834\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0486 - accuracy: 0.9851 - val_loss: 0.0646 - val_accuracy: 0.9808\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0434 - accuracy: 0.9864 - val_loss: 0.0605 - val_accuracy: 0.9818\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0373 - accuracy: 0.9882 - val_loss: 0.0525 - val_accuracy: 0.9849\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0324 - accuracy: 0.9897 - val_loss: 0.0462 - val_accuracy: 0.9862\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0301 - accuracy: 0.9906 - val_loss: 0.0487 - val_accuracy: 0.9855\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0390 - accuracy: 0.9876\n",
            "Test accuracy: 0.9876000285148621\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, AveragePooling2D, Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "\n",
        "# Load and preprocess the MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Reshape and normalize the images\n",
        "train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255\n",
        "\n",
        "# Convert labels to categorical one-hot encoding\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "# Define the LeNet model architecture\n",
        "def LeNet():\n",
        "    model = Sequential([\n",
        "        Conv2D(6, kernel_size=(5, 5), activation='relu', input_shape=(28, 28, 1)),\n",
        "        AveragePooling2D(),\n",
        "        Conv2D(16, kernel_size=(5, 5), activation='relu'),\n",
        "        AveragePooling2D(),\n",
        "        Flatten(),\n",
        "        Dense(120, activation='relu'),\n",
        "        Dense(84, activation='relu'),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Compile the model\n",
        "model = LeNet()\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss=CategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_images, train_labels, epochs=10, batch_size=128, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f'Test accuracy: {test_acc}')\n",
        "\n",
        "# Save the results\n",
        "results = {\n",
        "    'test_loss': test_loss,\n",
        "    'test_accuracy': test_acc,\n",
        "    'history': history.history\n",
        "}\n",
        "\n",
        "import json\n",
        "with open('lenet_mnist_results.json', 'w') as f:\n",
        "    json.dump(results, f)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LeNet Fashion MNIST\n"
      ],
      "metadata": {
        "id": "bjvG9mo-bFOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, AveragePooling2D, Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "\n",
        "# Load and preprocess the Fashion MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# Reshape and normalize the images\n",
        "train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255\n",
        "\n",
        "# Convert labels to categorical one-hot encoding\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "# Define the LeNet model architecture\n",
        "def LeNet():\n",
        "    model = Sequential([\n",
        "        Conv2D(6, kernel_size=(5, 5), activation='relu', input_shape=(28, 28, 1)),\n",
        "        AveragePooling2D(),\n",
        "        Conv2D(16, kernel_size=(5, 5), activation='relu'),\n",
        "        AveragePooling2D(),\n",
        "        Flatten(),\n",
        "        Dense(120, activation='relu'),\n",
        "        Dense(84, activation='relu'),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Compile the model\n",
        "model = LeNet()\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss=CategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_images, train_labels, epochs=10, batch_size=128, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f'Test accuracy: {test_acc}')\n",
        "\n",
        "# Save the results\n",
        "results = {\n",
        "    'test_loss': test_loss,\n",
        "    'test_accuracy': test_acc,\n",
        "    'history': history.history\n",
        "}\n",
        "\n",
        "import json\n",
        "with open('lenet_fashion_mnist_results.json', 'w') as f:\n",
        "    json.dump(results, f)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "boVpHjq_a57_",
        "outputId": "d1fe04f7-1d32-4168-df74-c811dfb144ad"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "375/375 [==============================] - 3s 5ms/step - loss: 0.7622 - accuracy: 0.7190 - val_loss: 0.5464 - val_accuracy: 0.7990\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.5077 - accuracy: 0.8157 - val_loss: 0.5066 - val_accuracy: 0.8091\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4405 - accuracy: 0.8412 - val_loss: 0.4274 - val_accuracy: 0.8438\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3978 - accuracy: 0.8564 - val_loss: 0.3940 - val_accuracy: 0.8567\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3736 - accuracy: 0.8644 - val_loss: 0.3722 - val_accuracy: 0.8673\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3515 - accuracy: 0.8717 - val_loss: 0.3729 - val_accuracy: 0.8668\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3330 - accuracy: 0.8785 - val_loss: 0.3584 - val_accuracy: 0.8707\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3204 - accuracy: 0.8822 - val_loss: 0.3472 - val_accuracy: 0.8749\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3092 - accuracy: 0.8872 - val_loss: 0.3292 - val_accuracy: 0.8799\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3010 - accuracy: 0.8902 - val_loss: 0.3389 - val_accuracy: 0.8748\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3536 - accuracy: 0.8673\n",
            "Test accuracy: 0.8672999739646912\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LeNet on CIFAR10"
      ],
      "metadata": {
        "id": "cnBqvoUMbdar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, AveragePooling2D, Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "\n",
        "# Load and preprocess the CIFAR-10 dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "\n",
        "# Normalize the images\n",
        "train_images = train_images.astype('float32') / 255\n",
        "test_images = test_images.astype('float32') / 255\n",
        "\n",
        "# Convert labels to categorical one-hot encoding\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "# Define the LeNet model architecture\n",
        "def LeNet():\n",
        "    model = Sequential([\n",
        "        Conv2D(6, kernel_size=(5, 5), activation='relu', input_shape=(32, 32, 3)),\n",
        "        AveragePooling2D(),\n",
        "        Conv2D(16, kernel_size=(5, 5), activation='relu'),\n",
        "        AveragePooling2D(),\n",
        "        Flatten(),\n",
        "        Dense(120, activation='relu'),\n",
        "        Dense(84, activation='relu'),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Compile the model\n",
        "model = LeNet()\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss=CategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_images, train_labels, epochs=20, batch_size=128, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f'Test accuracy: {test_acc}')\n",
        "\n",
        "# Save the results\n",
        "results = {\n",
        "    'test_loss': test_loss,\n",
        "    'test_accuracy': test_acc,\n",
        "    'history': history.history\n",
        "}\n",
        "\n",
        "import json\n",
        "with open('lenet_cifar10_results.json', 'w') as f:\n",
        "    json.dump(results, f)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3mgDQzxgbf_g",
        "outputId": "21c4712a-20cb-499e-c496-c880ea00e4e4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 13s 0us/step\n",
            "Epoch 1/20\n",
            "313/313 [==============================] - 4s 7ms/step - loss: 1.8498 - accuracy: 0.3273 - val_loss: 1.6244 - val_accuracy: 0.4200\n",
            "Epoch 2/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 1.5516 - accuracy: 0.4442 - val_loss: 1.5059 - val_accuracy: 0.4633\n",
            "Epoch 3/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 1.4382 - accuracy: 0.4803 - val_loss: 1.4229 - val_accuracy: 0.4865\n",
            "Epoch 4/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 1.3680 - accuracy: 0.5083 - val_loss: 1.3606 - val_accuracy: 0.5150\n",
            "Epoch 5/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 1.3046 - accuracy: 0.5342 - val_loss: 1.3248 - val_accuracy: 0.5257\n",
            "Epoch 6/20\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 1.2544 - accuracy: 0.5520 - val_loss: 1.2897 - val_accuracy: 0.5364\n",
            "Epoch 7/20\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 1.2175 - accuracy: 0.5627 - val_loss: 1.2632 - val_accuracy: 0.5581\n",
            "Epoch 8/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 1.1682 - accuracy: 0.5838 - val_loss: 1.2408 - val_accuracy: 0.5621\n",
            "Epoch 9/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 1.1380 - accuracy: 0.5951 - val_loss: 1.2276 - val_accuracy: 0.5688\n",
            "Epoch 10/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 1.1106 - accuracy: 0.6046 - val_loss: 1.2186 - val_accuracy: 0.5682\n",
            "Epoch 11/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 1.0767 - accuracy: 0.6187 - val_loss: 1.1895 - val_accuracy: 0.5862\n",
            "Epoch 12/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 1.0476 - accuracy: 0.6257 - val_loss: 1.2206 - val_accuracy: 0.5793\n",
            "Epoch 13/20\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 1.0247 - accuracy: 0.6352 - val_loss: 1.1869 - val_accuracy: 0.5920\n",
            "Epoch 14/20\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 1.0027 - accuracy: 0.6448 - val_loss: 1.1742 - val_accuracy: 0.5972\n",
            "Epoch 15/20\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.9706 - accuracy: 0.6574 - val_loss: 1.1780 - val_accuracy: 0.5973\n",
            "Epoch 16/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.9490 - accuracy: 0.6658 - val_loss: 1.1817 - val_accuracy: 0.5989\n",
            "Epoch 17/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.9249 - accuracy: 0.6712 - val_loss: 1.1996 - val_accuracy: 0.5886\n",
            "Epoch 18/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.9068 - accuracy: 0.6799 - val_loss: 1.1955 - val_accuracy: 0.5968\n",
            "Epoch 19/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.8879 - accuracy: 0.6852 - val_loss: 1.1799 - val_accuracy: 0.6030\n",
            "Epoch 20/20\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.8627 - accuracy: 0.6959 - val_loss: 1.1798 - val_accuracy: 0.6012\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 1.2014 - accuracy: 0.5894\n",
            "Test accuracy: 0.5893999934196472\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LeNet on CIFAR100"
      ],
      "metadata": {
        "id": "JF5MPPC0cCAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, AveragePooling2D, Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "\n",
        "# Load and preprocess the CIFAR-100 dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar100.load_data()\n",
        "\n",
        "# Normalize the images\n",
        "train_images = train_images.astype('float32') / 255\n",
        "test_images = test_images.astype('float32') / 255\n",
        "\n",
        "# Convert labels to categorical one-hot encoding\n",
        "train_labels = to_categorical(train_labels, 100)\n",
        "test_labels = to_categorical(test_labels, 100)\n",
        "\n",
        "# Define the LeNet model architecture\n",
        "def LeNet():\n",
        "    model = Sequential([\n",
        "        Conv2D(6, kernel_size=(5, 5), activation='relu', input_shape=(32, 32, 3)),\n",
        "        AveragePooling2D(),\n",
        "        Conv2D(16, kernel_size=(5, 5), activation='relu'),\n",
        "        AveragePooling2D(),\n",
        "        Flatten(),\n",
        "        Dense(120, activation='relu'),\n",
        "        Dense(84, activation='relu'),\n",
        "        Dense(100, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Compile the model\n",
        "model = LeNet()\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss=CategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_images, train_labels, epochs=20, batch_size=128, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f'Test accuracy: {test_acc}')\n",
        "\n",
        "# Save the results\n",
        "results = {\n",
        "    'test_loss': test_loss,\n",
        "    'test_accuracy': test_acc,\n",
        "    'history': history.history\n",
        "}\n",
        "\n",
        "import json\n",
        "with open('lenet_cifar100_results.json', 'w') as f:\n",
        "    json.dump(results, f)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "UPhaXnYAcD_a",
        "outputId": "0a466ee2-ebda-43d9-9094-1fd5a7cd20a9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169001437/169001437 [==============================] - 13s 0us/step\n",
            "Epoch 1/20\n",
            "313/313 [==============================] - 4s 7ms/step - loss: 4.1800 - accuracy: 0.0632 - val_loss: 3.9056 - val_accuracy: 0.1048\n",
            "Epoch 2/20\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 3.7796 - accuracy: 0.1234 - val_loss: 3.7158 - val_accuracy: 0.1377\n",
            "Epoch 3/20\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 3.6082 - accuracy: 0.1533 - val_loss: 3.5740 - val_accuracy: 0.1625\n",
            "Epoch 4/20\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 3.4799 - accuracy: 0.1760 - val_loss: 3.4735 - val_accuracy: 0.1775\n",
            "Epoch 5/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 3.3660 - accuracy: 0.1978 - val_loss: 3.4108 - val_accuracy: 0.1892\n",
            "Epoch 6/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 3.2828 - accuracy: 0.2139 - val_loss: 3.3548 - val_accuracy: 0.2023\n",
            "Epoch 7/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 3.2142 - accuracy: 0.2230 - val_loss: 3.3034 - val_accuracy: 0.2117\n",
            "Epoch 8/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 3.1569 - accuracy: 0.2330 - val_loss: 3.2815 - val_accuracy: 0.2168\n",
            "Epoch 9/20\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 3.1008 - accuracy: 0.2446 - val_loss: 3.2403 - val_accuracy: 0.2238\n",
            "Epoch 10/20\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 3.0530 - accuracy: 0.2550 - val_loss: 3.2135 - val_accuracy: 0.2302\n",
            "Epoch 11/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 3.0095 - accuracy: 0.2629 - val_loss: 3.2069 - val_accuracy: 0.2291\n",
            "Epoch 12/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 2.9828 - accuracy: 0.2693 - val_loss: 3.1788 - val_accuracy: 0.2394\n",
            "Epoch 13/20\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 2.9377 - accuracy: 0.2740 - val_loss: 3.1654 - val_accuracy: 0.2392\n",
            "Epoch 14/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 2.9033 - accuracy: 0.2833 - val_loss: 3.1356 - val_accuracy: 0.2419\n",
            "Epoch 15/20\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 2.8712 - accuracy: 0.2892 - val_loss: 3.1432 - val_accuracy: 0.2466\n",
            "Epoch 16/20\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 2.8380 - accuracy: 0.2930 - val_loss: 3.1291 - val_accuracy: 0.2478\n",
            "Epoch 17/20\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 2.8095 - accuracy: 0.2982 - val_loss: 3.1313 - val_accuracy: 0.2476\n",
            "Epoch 18/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 2.7825 - accuracy: 0.3069 - val_loss: 3.1407 - val_accuracy: 0.2504\n",
            "Epoch 19/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 2.7498 - accuracy: 0.3114 - val_loss: 3.1106 - val_accuracy: 0.2538\n",
            "Epoch 20/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 2.7240 - accuracy: 0.3162 - val_loss: 3.1048 - val_accuracy: 0.2542\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 3.0891 - accuracy: 0.2578\n",
            "Test accuracy: 0.25780001282691956\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "VGG on MNIST"
      ],
      "metadata": {
        "id": "1UgyfACycpzG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "\n",
        "# Load and preprocess the MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Reshape and normalize the images\n",
        "train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255\n",
        "\n",
        "# Convert labels to categorical one-hot encoding\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "# Define the VGG-style model architecture\n",
        "def VGG():\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(28, 28, 1)),\n",
        "        Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Dropout(0.25),\n",
        "\n",
        "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Dropout(0.25),\n",
        "\n",
        "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Dropout(0.25),\n",
        "\n",
        "        Flatten(),\n",
        "        Dense(512, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Compile the model\n",
        "model = VGG()\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss=CategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_images, train_labels, epochs=20, batch_size=128, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f'Test accuracy: {test_acc}')\n",
        "\n",
        "# Save the results\n",
        "results = {\n",
        "    'test_loss': test_loss,\n",
        "    'test_accuracy': test_acc,\n",
        "    'history': history.history\n",
        "}\n",
        "\n",
        "import json\n",
        "with open('vgg_mnist_results.json', 'w') as f:\n",
        "    json.dump(results, f)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "VuBLDER4cg1f",
        "outputId": "1dbd1edd-e419-427e-8fae-c6665732dc8e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "375/375 [==============================] - 10s 15ms/step - loss: 0.3030 - accuracy: 0.8999 - val_loss: 0.0599 - val_accuracy: 0.9826\n",
            "Epoch 2/20\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.0744 - accuracy: 0.9772 - val_loss: 0.0422 - val_accuracy: 0.9883\n",
            "Epoch 3/20\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.0521 - accuracy: 0.9837 - val_loss: 0.0426 - val_accuracy: 0.9876\n",
            "Epoch 4/20\n",
            "375/375 [==============================] - 5s 14ms/step - loss: 0.0431 - accuracy: 0.9866 - val_loss: 0.0297 - val_accuracy: 0.9918\n",
            "Epoch 5/20\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.0355 - accuracy: 0.9890 - val_loss: 0.0270 - val_accuracy: 0.9919\n",
            "Epoch 6/20\n",
            "375/375 [==============================] - 5s 14ms/step - loss: 0.0315 - accuracy: 0.9900 - val_loss: 0.0250 - val_accuracy: 0.9934\n",
            "Epoch 7/20\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.0276 - accuracy: 0.9913 - val_loss: 0.0276 - val_accuracy: 0.9927\n",
            "Epoch 8/20\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.0272 - accuracy: 0.9914 - val_loss: 0.0293 - val_accuracy: 0.9918\n",
            "Epoch 9/20\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.0247 - accuracy: 0.9920 - val_loss: 0.0289 - val_accuracy: 0.9918\n",
            "Epoch 10/20\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.0214 - accuracy: 0.9933 - val_loss: 0.0306 - val_accuracy: 0.9927\n",
            "Epoch 11/20\n",
            "375/375 [==============================] - 5s 14ms/step - loss: 0.0208 - accuracy: 0.9935 - val_loss: 0.0297 - val_accuracy: 0.9933\n",
            "Epoch 12/20\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.0185 - accuracy: 0.9944 - val_loss: 0.0252 - val_accuracy: 0.9936\n",
            "Epoch 13/20\n",
            "375/375 [==============================] - 5s 14ms/step - loss: 0.0187 - accuracy: 0.9941 - val_loss: 0.0289 - val_accuracy: 0.9926\n",
            "Epoch 14/20\n",
            "375/375 [==============================] - 5s 14ms/step - loss: 0.0176 - accuracy: 0.9948 - val_loss: 0.0268 - val_accuracy: 0.9933\n",
            "Epoch 15/20\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.0173 - accuracy: 0.9949 - val_loss: 0.0247 - val_accuracy: 0.9937\n",
            "Epoch 16/20\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.0165 - accuracy: 0.9949 - val_loss: 0.0265 - val_accuracy: 0.9933\n",
            "Epoch 17/20\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.0167 - accuracy: 0.9947 - val_loss: 0.0282 - val_accuracy: 0.9935\n",
            "Epoch 18/20\n",
            "375/375 [==============================] - 5s 14ms/step - loss: 0.0148 - accuracy: 0.9952 - val_loss: 0.0274 - val_accuracy: 0.9934\n",
            "Epoch 19/20\n",
            "375/375 [==============================] - 5s 14ms/step - loss: 0.0150 - accuracy: 0.9954 - val_loss: 0.0246 - val_accuracy: 0.9937\n",
            "Epoch 20/20\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.0126 - accuracy: 0.9960 - val_loss: 0.0244 - val_accuracy: 0.9933\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0178 - accuracy: 0.9948\n",
            "Test accuracy: 0.9947999715805054\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "VGG on Fashion-MNIST"
      ],
      "metadata": {
        "id": "XNv-ghRed3tC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "\n",
        "# Load and preprocess the Fashion MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# Reshape and normalize the images\n",
        "train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255\n",
        "\n",
        "# Convert labels to categorical one-hot encoding\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "# Define the VGG-style model architecture\n",
        "def VGG():\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(28, 28, 1)),\n",
        "        Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Dropout(0.25),\n",
        "\n",
        "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Dropout(0.25),\n",
        "\n",
        "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Dropout(0.25),\n",
        "\n",
        "        Flatten(),\n",
        "        Dense(512, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Compile the model\n",
        "model = VGG()\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss=CategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_images, train_labels, epochs=20, batch_size=128, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f'Test accuracy: {test_acc}')\n",
        "\n",
        "# Save the results\n",
        "results = {\n",
        "    'test_loss': test_loss,\n",
        "    'test_accuracy': test_acc,\n",
        "    'history': history.history\n",
        "}\n",
        "\n",
        "import json\n",
        "with open('vgg_fashion_mnist_results.json', 'w') as f:\n",
        "    json.dump(results, f)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "eHYU9Bwqd8Ax",
        "outputId": "e7a853dd-ed33-4f35-df4a-1bf026cc84aa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "375/375 [==============================] - 8s 14ms/step - loss: 0.6274 - accuracy: 0.7704 - val_loss: 0.3467 - val_accuracy: 0.8702\n",
            "Epoch 2/20\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.3549 - accuracy: 0.8693 - val_loss: 0.2981 - val_accuracy: 0.8921\n",
            "Epoch 3/20\n",
            "375/375 [==============================] - 5s 14ms/step - loss: 0.2971 - accuracy: 0.8901 - val_loss: 0.2865 - val_accuracy: 0.8912\n",
            "Epoch 4/20\n",
            "375/375 [==============================] - 5s 14ms/step - loss: 0.2720 - accuracy: 0.9013 - val_loss: 0.2365 - val_accuracy: 0.9133\n",
            "Epoch 5/20\n",
            "375/375 [==============================] - 5s 14ms/step - loss: 0.2515 - accuracy: 0.9071 - val_loss: 0.2219 - val_accuracy: 0.9174\n",
            "Epoch 6/20\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.2351 - accuracy: 0.9137 - val_loss: 0.2252 - val_accuracy: 0.9140\n",
            "Epoch 7/20\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.2222 - accuracy: 0.9176 - val_loss: 0.2170 - val_accuracy: 0.9182\n",
            "Epoch 8/20\n",
            "375/375 [==============================] - 5s 14ms/step - loss: 0.2120 - accuracy: 0.9213 - val_loss: 0.2089 - val_accuracy: 0.9227\n",
            "Epoch 9/20\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.1989 - accuracy: 0.9260 - val_loss: 0.2011 - val_accuracy: 0.9265\n",
            "Epoch 10/20\n",
            "375/375 [==============================] - 5s 15ms/step - loss: 0.1929 - accuracy: 0.9278 - val_loss: 0.2014 - val_accuracy: 0.9268\n",
            "Epoch 11/20\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.1856 - accuracy: 0.9312 - val_loss: 0.1925 - val_accuracy: 0.9302\n",
            "Epoch 12/20\n",
            "375/375 [==============================] - 5s 14ms/step - loss: 0.1781 - accuracy: 0.9330 - val_loss: 0.1904 - val_accuracy: 0.9321\n",
            "Epoch 13/20\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.1699 - accuracy: 0.9370 - val_loss: 0.1985 - val_accuracy: 0.9302\n",
            "Epoch 14/20\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.1617 - accuracy: 0.9403 - val_loss: 0.1973 - val_accuracy: 0.9303\n",
            "Epoch 15/20\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.1574 - accuracy: 0.9417 - val_loss: 0.2003 - val_accuracy: 0.9302\n",
            "Epoch 16/20\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.1516 - accuracy: 0.9429 - val_loss: 0.1945 - val_accuracy: 0.9327\n",
            "Epoch 17/20\n",
            "375/375 [==============================] - 5s 14ms/step - loss: 0.1476 - accuracy: 0.9448 - val_loss: 0.1986 - val_accuracy: 0.9302\n",
            "Epoch 18/20\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.1433 - accuracy: 0.9460 - val_loss: 0.1966 - val_accuracy: 0.9307\n",
            "Epoch 19/20\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.1363 - accuracy: 0.9476 - val_loss: 0.2010 - val_accuracy: 0.9315\n",
            "Epoch 20/20\n",
            "375/375 [==============================] - 5s 14ms/step - loss: 0.1360 - accuracy: 0.9503 - val_loss: 0.2057 - val_accuracy: 0.9283\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.2260 - accuracy: 0.9273\n",
            "Test accuracy: 0.927299976348877\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "VGG on CIFAR10"
      ],
      "metadata": {
        "id": "Wlm3qU5aeLe8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "\n",
        "# Load and preprocess the CIFAR-10 dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "\n",
        "# Normalize the images\n",
        "train_images = train_images.astype('float32') / 255\n",
        "test_images = test_images.astype('float32') / 255\n",
        "\n",
        "# Convert labels to categorical one-hot encoding\n",
        "train_labels = to_categorical(train_labels, 10)\n",
        "test_labels = to_categorical(test_labels, 10)\n",
        "\n",
        "# Define the VGG-style model architecture\n",
        "def VGG():\n",
        "    model = Sequential([\n",
        "        Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)),\n",
        "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Dropout(0.25),\n",
        "\n",
        "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Dropout(0.25),\n",
        "\n",
        "        Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "        Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "        Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Dropout(0.25),\n",
        "\n",
        "        Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
        "        Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
        "        Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Dropout(0.25),\n",
        "\n",
        "        Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
        "        Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
        "        Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Dropout(0.25),\n",
        "\n",
        "        Flatten(),\n",
        "        Dense(512, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(512, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Compile the model\n",
        "model = VGG()\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss=CategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_images, train_labels, epochs=50, batch_size=128, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f'Test accuracy: {test_acc}')\n",
        "\n",
        "# Save the results\n",
        "results = {\n",
        "    'test_loss': test_loss,\n",
        "    'test_accuracy': test_acc,\n",
        "    'history': history.history\n",
        "}\n",
        "\n",
        "import json\n",
        "with open('vgg_cifar10_results.json', 'w') as f:\n",
        "    json.dump(results, f)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "1z0c_yujeOXY",
        "outputId": "198ef033-1e1c-4e42-cdbb-4e115a4e452e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "313/313 [==============================] - 31s 72ms/step - loss: 2.3051 - accuracy: 0.0997 - val_loss: 2.3026 - val_accuracy: 0.0997\n",
            "Epoch 2/50\n",
            "313/313 [==============================] - 19s 61ms/step - loss: 2.3032 - accuracy: 0.0981 - val_loss: 2.3027 - val_accuracy: 0.0980\n",
            "Epoch 3/50\n",
            "313/313 [==============================] - 19s 61ms/step - loss: 2.3028 - accuracy: 0.1008 - val_loss: 2.3031 - val_accuracy: 0.0952\n",
            "Epoch 4/50\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 2.3028 - accuracy: 0.1004 - val_loss: 2.3029 - val_accuracy: 0.0977\n",
            "Epoch 5/50\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 2.3027 - accuracy: 0.0994 - val_loss: 2.3028 - val_accuracy: 0.0977\n",
            "Epoch 6/50\n",
            "313/313 [==============================] - 19s 61ms/step - loss: 2.3028 - accuracy: 0.0982 - val_loss: 2.3028 - val_accuracy: 0.0997\n",
            "Epoch 7/50\n",
            "313/313 [==============================] - 19s 61ms/step - loss: 2.3027 - accuracy: 0.0985 - val_loss: 2.3028 - val_accuracy: 0.0997\n",
            "Epoch 8/50\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 2.3027 - accuracy: 0.0986 - val_loss: 2.3027 - val_accuracy: 0.0952\n",
            "Epoch 9/50\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 2.3027 - accuracy: 0.0998 - val_loss: 2.3028 - val_accuracy: 0.0952\n",
            "Epoch 10/50\n",
            "313/313 [==============================] - 19s 62ms/step - loss: 2.3027 - accuracy: 0.0988 - val_loss: 2.3027 - val_accuracy: 0.0997\n",
            "Epoch 11/50\n",
            "313/313 [==============================] - 19s 62ms/step - loss: 2.3027 - accuracy: 0.1023 - val_loss: 2.3026 - val_accuracy: 0.0952\n",
            "Epoch 12/50\n",
            "313/313 [==============================] - 19s 61ms/step - loss: 2.3027 - accuracy: 0.1006 - val_loss: 2.3027 - val_accuracy: 0.0997\n",
            "Epoch 13/50\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 2.3027 - accuracy: 0.0988 - val_loss: 2.3027 - val_accuracy: 0.0997\n",
            "Epoch 14/50\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 2.3027 - accuracy: 0.0983 - val_loss: 2.3026 - val_accuracy: 0.0997\n",
            "Epoch 15/50\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 2.3027 - accuracy: 0.0977 - val_loss: 2.3027 - val_accuracy: 0.0952\n",
            "Epoch 16/50\n",
            "313/313 [==============================] - 19s 61ms/step - loss: 2.3027 - accuracy: 0.1005 - val_loss: 2.3027 - val_accuracy: 0.0952\n",
            "Epoch 17/50\n",
            "313/313 [==============================] - 19s 61ms/step - loss: 2.3027 - accuracy: 0.1007 - val_loss: 2.3027 - val_accuracy: 0.0977\n",
            "Epoch 18/50\n",
            "313/313 [==============================] - 19s 61ms/step - loss: 2.3027 - accuracy: 0.0983 - val_loss: 2.3027 - val_accuracy: 0.0980\n",
            "Epoch 19/50\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 2.3027 - accuracy: 0.1008 - val_loss: 2.3027 - val_accuracy: 0.0952\n",
            "Epoch 20/50\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 2.3027 - accuracy: 0.0990 - val_loss: 2.3028 - val_accuracy: 0.0952\n",
            "Epoch 21/50\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 2.3027 - accuracy: 0.1004 - val_loss: 2.3028 - val_accuracy: 0.0952\n",
            "Epoch 22/50\n",
            "313/313 [==============================] - 19s 59ms/step - loss: 2.3027 - accuracy: 0.1015 - val_loss: 2.3028 - val_accuracy: 0.0977\n",
            "Epoch 23/50\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 2.3027 - accuracy: 0.1005 - val_loss: 2.3027 - val_accuracy: 0.0980\n",
            "Epoch 24/50\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 2.3027 - accuracy: 0.0965 - val_loss: 2.3027 - val_accuracy: 0.0952\n",
            "Epoch 25/50\n",
            "313/313 [==============================] - 19s 61ms/step - loss: 2.3027 - accuracy: 0.0997 - val_loss: 2.3027 - val_accuracy: 0.0952\n",
            "Epoch 26/50\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 2.3027 - accuracy: 0.0989 - val_loss: 2.3028 - val_accuracy: 0.0952\n",
            "Epoch 27/50\n",
            "313/313 [==============================] - 19s 59ms/step - loss: 2.3027 - accuracy: 0.1012 - val_loss: 2.3027 - val_accuracy: 0.0952\n",
            "Epoch 28/50\n",
            "313/313 [==============================] - 19s 61ms/step - loss: 2.3027 - accuracy: 0.0961 - val_loss: 2.3028 - val_accuracy: 0.0952\n",
            "Epoch 29/50\n",
            "313/313 [==============================] - 19s 59ms/step - loss: 2.3027 - accuracy: 0.1012 - val_loss: 2.3027 - val_accuracy: 0.0952\n",
            "Epoch 30/50\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 2.3027 - accuracy: 0.0990 - val_loss: 2.3027 - val_accuracy: 0.0952\n",
            "Epoch 31/50\n",
            "313/313 [==============================] - 19s 59ms/step - loss: 2.3027 - accuracy: 0.0983 - val_loss: 2.3027 - val_accuracy: 0.0952\n",
            "Epoch 32/50\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 2.3027 - accuracy: 0.0993 - val_loss: 2.3027 - val_accuracy: 0.0952\n",
            "Epoch 33/50\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 2.3027 - accuracy: 0.0989 - val_loss: 2.3027 - val_accuracy: 0.0952\n",
            "Epoch 34/50\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 2.3027 - accuracy: 0.0989 - val_loss: 2.3028 - val_accuracy: 0.0952\n",
            "Epoch 35/50\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 2.3027 - accuracy: 0.1009 - val_loss: 2.3027 - val_accuracy: 0.0977\n",
            "Epoch 36/50\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 2.3027 - accuracy: 0.0985 - val_loss: 2.3027 - val_accuracy: 0.0952\n",
            "Epoch 37/50\n",
            "313/313 [==============================] - 19s 62ms/step - loss: 2.3027 - accuracy: 0.1007 - val_loss: 2.3027 - val_accuracy: 0.0952\n",
            "Epoch 38/50\n",
            "313/313 [==============================] - 19s 59ms/step - loss: 2.3027 - accuracy: 0.0983 - val_loss: 2.3027 - val_accuracy: 0.0952\n",
            "Epoch 39/50\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 2.3027 - accuracy: 0.1003 - val_loss: 2.3027 - val_accuracy: 0.0952\n",
            "Epoch 40/50\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 2.3027 - accuracy: 0.0981 - val_loss: 2.3027 - val_accuracy: 0.0977\n",
            "Epoch 41/50\n",
            "313/313 [==============================] - 19s 61ms/step - loss: 2.3027 - accuracy: 0.1013 - val_loss: 2.3027 - val_accuracy: 0.0952\n",
            "Epoch 42/50\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 2.3027 - accuracy: 0.1007 - val_loss: 2.3028 - val_accuracy: 0.0980\n",
            "Epoch 43/50\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 2.3027 - accuracy: 0.1000 - val_loss: 2.3027 - val_accuracy: 0.0977\n",
            "Epoch 44/50\n",
            "313/313 [==============================] - 19s 59ms/step - loss: 2.3027 - accuracy: 0.0997 - val_loss: 2.3027 - val_accuracy: 0.0952\n",
            "Epoch 45/50\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 2.3027 - accuracy: 0.0996 - val_loss: 2.3027 - val_accuracy: 0.0952\n",
            "Epoch 46/50\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 2.3027 - accuracy: 0.1000 - val_loss: 2.3028 - val_accuracy: 0.0980\n",
            "Epoch 47/50\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 2.3027 - accuracy: 0.0996 - val_loss: 2.3027 - val_accuracy: 0.0952\n",
            "Epoch 48/50\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 2.3027 - accuracy: 0.0998 - val_loss: 2.3027 - val_accuracy: 0.0952\n",
            "Epoch 49/50\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 2.3027 - accuracy: 0.1004 - val_loss: 2.3027 - val_accuracy: 0.0952\n",
            "Epoch 50/50\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 2.3027 - accuracy: 0.1012 - val_loss: 2.3027 - val_accuracy: 0.0952\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 2.3026 - accuracy: 0.1000\n",
            "Test accuracy: 0.10000000149011612\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "VGG on CIFAR100"
      ],
      "metadata": {
        "id": "TieGj1n5edpk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "\n",
        "# Load and preprocess the CIFAR-100 dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar100.load_data()\n",
        "\n",
        "# Normalize the images\n",
        "train_images = train_images.astype('float32') / 255\n",
        "test_images = test_images.astype('float32') / 255\n",
        "\n",
        "# Convert labels to categorical one-hot encoding\n",
        "train_labels = to_categorical(train_labels, 100)\n",
        "test_labels = to_categorical(test_labels, 100)\n",
        "\n",
        "# Define the VGG-style model architecture\n",
        "def VGG():\n",
        "    model = Sequential([\n",
        "        Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)),\n",
        "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Dropout(0.25),\n",
        "\n",
        "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Dropout(0.25),\n",
        "\n",
        "        Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "        Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "        Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Dropout(0.25),\n",
        "\n",
        "        Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
        "        Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
        "        Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Dropout(0.25),\n",
        "\n",
        "        Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
        "        Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
        "        Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Dropout(0.25),\n",
        "\n",
        "        Flatten(),\n",
        "        Dense(512, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(512, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(100, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Compile the model\n",
        "model = VGG()\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss=CategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_images, train_labels, epochs=50, batch_size=128, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f'Test accuracy: {test_acc}')\n",
        "\n",
        "# Save the results\n",
        "results = {\n",
        "    'test_loss': test_loss,\n",
        "    'test_accuracy': test_acc,\n",
        "    'history': history.history\n",
        "}\n",
        "\n",
        "import json\n",
        "with open('vgg_cifar100_results.json', 'w') as f:\n",
        "    json.dump(results, f)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "wcJr5_1WeeRD",
        "outputId": "a035c184-4ee4-486f-ef99-41b49c263421"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "313/313 [==============================] - 24s 62ms/step - loss: 4.6064 - accuracy: 0.0089 - val_loss: 4.6065 - val_accuracy: 0.0084\n",
            "Epoch 2/50\n",
            "313/313 [==============================] - 19s 61ms/step - loss: 4.6057 - accuracy: 0.0092 - val_loss: 4.6067 - val_accuracy: 0.0083\n",
            "Epoch 3/50\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 4.6055 - accuracy: 0.0094 - val_loss: 4.6069 - val_accuracy: 0.0084\n",
            "Epoch 4/50\n",
            "313/313 [==============================] - 19s 61ms/step - loss: 4.6054 - accuracy: 0.0093 - val_loss: 4.6071 - val_accuracy: 0.0077\n",
            "Epoch 5/50\n",
            "313/313 [==============================] - 19s 61ms/step - loss: 4.6053 - accuracy: 0.0097 - val_loss: 4.6074 - val_accuracy: 0.0077\n",
            "Epoch 6/50\n",
            "313/313 [==============================] - 19s 62ms/step - loss: 4.6053 - accuracy: 0.0095 - val_loss: 4.6075 - val_accuracy: 0.0077\n",
            "Epoch 7/50\n",
            "313/313 [==============================] - 19s 61ms/step - loss: 4.6053 - accuracy: 0.0105 - val_loss: 4.6076 - val_accuracy: 0.0077\n",
            "Epoch 8/50\n",
            "313/313 [==============================] - 19s 61ms/step - loss: 4.6053 - accuracy: 0.0100 - val_loss: 4.6077 - val_accuracy: 0.0077\n",
            "Epoch 9/50\n",
            "313/313 [==============================] - 19s 61ms/step - loss: 4.6053 - accuracy: 0.0096 - val_loss: 4.6077 - val_accuracy: 0.0077\n",
            "Epoch 10/50\n",
            "313/313 [==============================] - 19s 61ms/step - loss: 4.6052 - accuracy: 0.0103 - val_loss: 4.6078 - val_accuracy: 0.0077\n",
            "Epoch 11/50\n",
            "313/313 [==============================] - 19s 61ms/step - loss: 4.6053 - accuracy: 0.0106 - val_loss: 4.6078 - val_accuracy: 0.0077\n",
            "Epoch 12/50\n",
            "313/313 [==============================] - 19s 62ms/step - loss: 4.6053 - accuracy: 0.0101 - val_loss: 4.6079 - val_accuracy: 0.0077\n",
            "Epoch 13/50\n",
            "313/313 [==============================] - 19s 61ms/step - loss: 4.6053 - accuracy: 0.0102 - val_loss: 4.6079 - val_accuracy: 0.0077\n",
            "Epoch 14/50\n",
            "313/313 [==============================] - 19s 61ms/step - loss: 4.6053 - accuracy: 0.0102 - val_loss: 4.6079 - val_accuracy: 0.0077\n",
            "Epoch 15/50\n",
            "313/313 [==============================] - 19s 61ms/step - loss: 4.6053 - accuracy: 0.0099 - val_loss: 4.6079 - val_accuracy: 0.0077\n",
            "Epoch 16/50\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 4.6053 - accuracy: 0.0106 - val_loss: 4.6080 - val_accuracy: 0.0077\n",
            "Epoch 17/50\n",
            "313/313 [==============================] - 19s 61ms/step - loss: 4.6053 - accuracy: 0.0106 - val_loss: 4.6080 - val_accuracy: 0.0077\n",
            "Epoch 18/50\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 4.6053 - accuracy: 0.0097 - val_loss: 4.6079 - val_accuracy: 0.0077\n",
            "Epoch 19/50\n",
            "313/313 [==============================] - 19s 61ms/step - loss: 4.6053 - accuracy: 0.0101 - val_loss: 4.6080 - val_accuracy: 0.0077\n",
            "Epoch 20/50\n",
            "313/313 [==============================] - 19s 61ms/step - loss: 4.6053 - accuracy: 0.0103 - val_loss: 4.6080 - val_accuracy: 0.0077\n",
            "Epoch 21/50\n",
            "313/313 [==============================] - 19s 61ms/step - loss: 4.6053 - accuracy: 0.0104 - val_loss: 4.6080 - val_accuracy: 0.0077\n",
            "Epoch 22/50\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 4.6052 - accuracy: 0.0106 - val_loss: 4.6080 - val_accuracy: 0.0077\n",
            "Epoch 23/50\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 4.6053 - accuracy: 0.0100 - val_loss: 4.6080 - val_accuracy: 0.0077\n",
            "Epoch 24/50\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 4.6052 - accuracy: 0.0100 - val_loss: 4.6080 - val_accuracy: 0.0077\n",
            "Epoch 25/50\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 4.6052 - accuracy: 0.0103 - val_loss: 4.6080 - val_accuracy: 0.0077\n",
            "Epoch 26/50\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 4.6053 - accuracy: 0.0106 - val_loss: 4.6080 - val_accuracy: 0.0077\n",
            "Epoch 27/50\n",
            "313/313 [==============================] - 19s 61ms/step - loss: 4.6053 - accuracy: 0.0102 - val_loss: 4.6080 - val_accuracy: 0.0077\n",
            "Epoch 28/50\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 4.6053 - accuracy: 0.0106 - val_loss: 4.6079 - val_accuracy: 0.0077\n",
            "Epoch 29/50\n",
            "313/313 [==============================] - 19s 61ms/step - loss: 4.6052 - accuracy: 0.0103 - val_loss: 4.6080 - val_accuracy: 0.0077\n",
            "Epoch 30/50\n",
            "313/313 [==============================] - 19s 62ms/step - loss: 4.6053 - accuracy: 0.0104 - val_loss: 4.6079 - val_accuracy: 0.0077\n",
            "Epoch 31/50\n",
            "313/313 [==============================] - 19s 62ms/step - loss: 4.6053 - accuracy: 0.0106 - val_loss: 4.6079 - val_accuracy: 0.0077\n",
            "Epoch 32/50\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 4.6053 - accuracy: 0.0097 - val_loss: 4.6080 - val_accuracy: 0.0077\n",
            "Epoch 33/50\n",
            "313/313 [==============================] - 19s 61ms/step - loss: 4.6052 - accuracy: 0.0102 - val_loss: 4.6080 - val_accuracy: 0.0077\n",
            "Epoch 34/50\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 4.6053 - accuracy: 0.0104 - val_loss: 4.6080 - val_accuracy: 0.0077\n",
            "Epoch 35/50\n",
            "313/313 [==============================] - 19s 61ms/step - loss: 4.6052 - accuracy: 0.0097 - val_loss: 4.6079 - val_accuracy: 0.0077\n",
            "Epoch 36/50\n",
            "313/313 [==============================] - 19s 61ms/step - loss: 4.6053 - accuracy: 0.0104 - val_loss: 4.6079 - val_accuracy: 0.0077\n",
            "Epoch 37/50\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 4.6053 - accuracy: 0.0104 - val_loss: 4.6079 - val_accuracy: 0.0077\n",
            "Epoch 38/50\n",
            "313/313 [==============================] - 19s 61ms/step - loss: 4.6053 - accuracy: 0.0103 - val_loss: 4.6080 - val_accuracy: 0.0077\n",
            "Epoch 39/50\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 4.6053 - accuracy: 0.0106 - val_loss: 4.6080 - val_accuracy: 0.0077\n",
            "Epoch 40/50\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 4.6053 - accuracy: 0.0100 - val_loss: 4.6080 - val_accuracy: 0.0077\n",
            "Epoch 41/50\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 4.6052 - accuracy: 0.0099 - val_loss: 4.6079 - val_accuracy: 0.0077\n",
            "Epoch 42/50\n",
            "313/313 [==============================] - 19s 61ms/step - loss: 4.6053 - accuracy: 0.0106 - val_loss: 4.6080 - val_accuracy: 0.0077\n",
            "Epoch 43/50\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 4.6052 - accuracy: 0.0106 - val_loss: 4.6079 - val_accuracy: 0.0077\n",
            "Epoch 44/50\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 4.6052 - accuracy: 0.0106 - val_loss: 4.6079 - val_accuracy: 0.0077\n",
            "Epoch 45/50\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 4.6053 - accuracy: 0.0098 - val_loss: 4.6079 - val_accuracy: 0.0077\n",
            "Epoch 46/50\n",
            "313/313 [==============================] - 19s 61ms/step - loss: 4.6053 - accuracy: 0.0103 - val_loss: 4.6079 - val_accuracy: 0.0077\n",
            "Epoch 47/50\n",
            "313/313 [==============================] - 19s 61ms/step - loss: 4.6053 - accuracy: 0.0106 - val_loss: 4.6079 - val_accuracy: 0.0077\n",
            "Epoch 48/50\n",
            "313/313 [==============================] - 19s 61ms/step - loss: 4.6053 - accuracy: 0.0102 - val_loss: 4.6079 - val_accuracy: 0.0077\n",
            "Epoch 49/50\n",
            "313/313 [==============================] - 19s 62ms/step - loss: 4.6052 - accuracy: 0.0098 - val_loss: 4.6080 - val_accuracy: 0.0077\n",
            "Epoch 50/50\n",
            "313/313 [==============================] - 19s 61ms/step - loss: 4.6052 - accuracy: 0.0106 - val_loss: 4.6079 - val_accuracy: 0.0077\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 4.6055 - accuracy: 0.0100\n",
            "Test accuracy: 0.009999999776482582\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ResNet on MNIST"
      ],
      "metadata": {
        "id": "M7jpD-s9fAAT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, Add, Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "\n",
        "# Load and preprocess the MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Reshape and normalize the images\n",
        "train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255\n",
        "\n",
        "# Convert labels to categorical one-hot encoding\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "# Define the ResNet model architecture\n",
        "def resnet_block(input_tensor, filters, kernel_size=3, stride=1):\n",
        "    x = Conv2D(filters, kernel_size=kernel_size, strides=stride, padding='same')(input_tensor)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(filters, kernel_size=kernel_size, strides=1, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    if stride != 1:\n",
        "        input_tensor = Conv2D(filters, kernel_size=1, strides=stride, padding='same')(input_tensor)\n",
        "        input_tensor = BatchNormalization()(input_tensor)\n",
        "\n",
        "    x = Add()([x, input_tensor])\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def ResNet(input_shape, num_classes):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = Conv2D(32, kernel_size=3, strides=1, padding='same')(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = resnet_block(x, 32)\n",
        "    x = resnet_block(x, 32)\n",
        "    x = resnet_block(x, 64, stride=2)\n",
        "    x = resnet_block(x, 64)\n",
        "    x = resnet_block(x, 128, stride=2)\n",
        "    x = resnet_block(x, 128)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs, x)\n",
        "    return model\n",
        "\n",
        "# Compile the model\n",
        "model = ResNet(input_shape=(28, 28, 1), num_classes=10)\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss=CategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_images, train_labels, epochs=20, batch_size=128, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f'Test accuracy: {test_acc}')\n",
        "\n",
        "# Save the results\n",
        "results = {\n",
        "    'test_loss': test_loss,\n",
        "    'test_accuracy': test_acc,\n",
        "    'history': history.history\n",
        "}\n",
        "\n",
        "import json\n",
        "with open('resnet_mnist_results.json', 'w') as f:\n",
        "    json.dump(results, f)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "iQqY0taVfChU",
        "outputId": "76546bc7-c728-4383-a0c3-152b76a893b9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "375/375 [==============================] - 25s 42ms/step - loss: 0.2934 - accuracy: 0.9395 - val_loss: 1.5562 - val_accuracy: 0.5062\n",
            "Epoch 2/20\n",
            "375/375 [==============================] - 14s 37ms/step - loss: 0.0461 - accuracy: 0.9860 - val_loss: 0.0823 - val_accuracy: 0.9764\n",
            "Epoch 3/20\n",
            "375/375 [==============================] - 14s 37ms/step - loss: 0.0364 - accuracy: 0.9889 - val_loss: 0.0759 - val_accuracy: 0.9801\n",
            "Epoch 4/20\n",
            "375/375 [==============================] - 13s 36ms/step - loss: 0.0241 - accuracy: 0.9924 - val_loss: 0.0484 - val_accuracy: 0.9867\n",
            "Epoch 5/20\n",
            "375/375 [==============================] - 14s 36ms/step - loss: 0.0217 - accuracy: 0.9929 - val_loss: 0.0560 - val_accuracy: 0.9868\n",
            "Epoch 6/20\n",
            "375/375 [==============================] - 13s 35ms/step - loss: 0.0230 - accuracy: 0.9923 - val_loss: 0.0618 - val_accuracy: 0.9836\n",
            "Epoch 7/20\n",
            "375/375 [==============================] - 14s 37ms/step - loss: 0.0197 - accuracy: 0.9938 - val_loss: 0.0457 - val_accuracy: 0.9879\n",
            "Epoch 8/20\n",
            "375/375 [==============================] - 14s 36ms/step - loss: 0.0152 - accuracy: 0.9950 - val_loss: 0.0753 - val_accuracy: 0.9810\n",
            "Epoch 9/20\n",
            "375/375 [==============================] - 14s 36ms/step - loss: 0.0175 - accuracy: 0.9949 - val_loss: 0.0570 - val_accuracy: 0.9868\n",
            "Epoch 10/20\n",
            "375/375 [==============================] - 14s 37ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.0808 - val_accuracy: 0.9795\n",
            "Epoch 11/20\n",
            "375/375 [==============================] - 13s 36ms/step - loss: 0.0144 - accuracy: 0.9954 - val_loss: 0.0819 - val_accuracy: 0.9807\n",
            "Epoch 12/20\n",
            "375/375 [==============================] - 13s 36ms/step - loss: 0.0112 - accuracy: 0.9964 - val_loss: 0.0545 - val_accuracy: 0.9871\n",
            "Epoch 13/20\n",
            "375/375 [==============================] - 14s 36ms/step - loss: 0.0130 - accuracy: 0.9958 - val_loss: 0.0448 - val_accuracy: 0.9906\n",
            "Epoch 14/20\n",
            "375/375 [==============================] - 14s 36ms/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 0.0390 - val_accuracy: 0.9896\n",
            "Epoch 15/20\n",
            "375/375 [==============================] - 14s 37ms/step - loss: 0.0131 - accuracy: 0.9960 - val_loss: 0.0507 - val_accuracy: 0.9890\n",
            "Epoch 16/20\n",
            "375/375 [==============================] - 14s 37ms/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 0.0550 - val_accuracy: 0.9876\n",
            "Epoch 17/20\n",
            "375/375 [==============================] - 14s 36ms/step - loss: 0.0069 - accuracy: 0.9978 - val_loss: 0.0512 - val_accuracy: 0.9882\n",
            "Epoch 18/20\n",
            "375/375 [==============================] - 14s 37ms/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.0405 - val_accuracy: 0.9910\n",
            "Epoch 19/20\n",
            "375/375 [==============================] - 14s 37ms/step - loss: 0.0104 - accuracy: 0.9966 - val_loss: 0.0408 - val_accuracy: 0.9899\n",
            "Epoch 20/20\n",
            "375/375 [==============================] - 14s 37ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.0522 - val_accuracy: 0.9900\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0344 - accuracy: 0.9923\n",
            "Test accuracy: 0.9922999739646912\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ResNet on Fashion-MNIST"
      ],
      "metadata": {
        "id": "ObGdr9MIfDwr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, Add, Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "\n",
        "# Load and preprocess the Fashion MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# Reshape and normalize the images\n",
        "train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255\n",
        "\n",
        "# Convert labels to categorical one-hot encoding\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "# Define the ResNet model architecture\n",
        "def resnet_block(input_tensor, filters, kernel_size=3, stride=1):\n",
        "    x = Conv2D(filters, kernel_size=kernel_size, strides=stride, padding='same')(input_tensor)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(filters, kernel_size=kernel_size, strides=1, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    if stride != 1:\n",
        "        input_tensor = Conv2D(filters, kernel_size=1, strides=stride, padding='same')(input_tensor)\n",
        "        input_tensor = BatchNormalization()(input_tensor)\n",
        "\n",
        "    x = Add()([x, input_tensor])\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def ResNet(input_shape, num_classes):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = Conv2D(32, kernel_size=3, strides=1, padding='same')(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = resnet_block(x, 32)\n",
        "    x = resnet_block(x, 32)\n",
        "    x = resnet_block(x, 64, stride=2)\n",
        "    x = resnet_block(x, 64)\n",
        "    x = resnet_block(x, 128, stride=2)\n",
        "    x = resnet_block(x, 128)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs, x)\n",
        "    return model\n",
        "\n",
        "# Compile the model\n",
        "model = ResNet(input_shape=(28, 28, 1), num_classes=10)\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss=CategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_images, train_labels, epochs=20, batch_size=128, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f'Test accuracy: {test_acc}')\n",
        "\n",
        "# Save the results\n",
        "results = {\n",
        "    'test_loss': test_loss,\n",
        "    'test_accuracy': test_acc,\n",
        "    'history': history.history\n",
        "}\n",
        "\n",
        "import json\n",
        "with open('resnet_fashion_mnist_results.json', 'w') as f:\n",
        "    json.dump(results, f)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ZlM38QtVfJUO",
        "outputId": "f4f6f2e3-e88a-4445-e433-44da2ac5bf45"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "375/375 [==============================] - 23s 37ms/step - loss: 0.5958 - accuracy: 0.8256 - val_loss: 1.0386 - val_accuracy: 0.6621\n",
            "Epoch 2/20\n",
            "375/375 [==============================] - 14s 36ms/step - loss: 0.2634 - accuracy: 0.9045 - val_loss: 0.2647 - val_accuracy: 0.9089\n",
            "Epoch 3/20\n",
            "375/375 [==============================] - 14s 36ms/step - loss: 0.2064 - accuracy: 0.9246 - val_loss: 0.2668 - val_accuracy: 0.9022\n",
            "Epoch 4/20\n",
            "375/375 [==============================] - 14s 37ms/step - loss: 0.1720 - accuracy: 0.9357 - val_loss: 0.2598 - val_accuracy: 0.9108\n",
            "Epoch 5/20\n",
            "375/375 [==============================] - 14s 37ms/step - loss: 0.1416 - accuracy: 0.9474 - val_loss: 0.3288 - val_accuracy: 0.8956\n",
            "Epoch 6/20\n",
            "375/375 [==============================] - 13s 36ms/step - loss: 0.1174 - accuracy: 0.9566 - val_loss: 0.2469 - val_accuracy: 0.9159\n",
            "Epoch 7/20\n",
            "375/375 [==============================] - 14s 36ms/step - loss: 0.1001 - accuracy: 0.9637 - val_loss: 0.2487 - val_accuracy: 0.9205\n",
            "Epoch 8/20\n",
            "375/375 [==============================] - 14s 36ms/step - loss: 0.0793 - accuracy: 0.9707 - val_loss: 0.2499 - val_accuracy: 0.9179\n",
            "Epoch 9/20\n",
            "375/375 [==============================] - 14s 37ms/step - loss: 0.0634 - accuracy: 0.9770 - val_loss: 0.3024 - val_accuracy: 0.9154\n",
            "Epoch 10/20\n",
            "375/375 [==============================] - 14s 37ms/step - loss: 0.0523 - accuracy: 0.9802 - val_loss: 0.3105 - val_accuracy: 0.9162\n",
            "Epoch 11/20\n",
            "375/375 [==============================] - 14s 36ms/step - loss: 0.0482 - accuracy: 0.9823 - val_loss: 0.3611 - val_accuracy: 0.9156\n",
            "Epoch 12/20\n",
            "375/375 [==============================] - 13s 36ms/step - loss: 0.0370 - accuracy: 0.9867 - val_loss: 0.3547 - val_accuracy: 0.9193\n",
            "Epoch 13/20\n",
            "375/375 [==============================] - 13s 36ms/step - loss: 0.0374 - accuracy: 0.9863 - val_loss: 0.3962 - val_accuracy: 0.9112\n",
            "Epoch 14/20\n",
            "375/375 [==============================] - 13s 36ms/step - loss: 0.0322 - accuracy: 0.9883 - val_loss: 0.3440 - val_accuracy: 0.9238\n",
            "Epoch 15/20\n",
            "375/375 [==============================] - 13s 35ms/step - loss: 0.0284 - accuracy: 0.9900 - val_loss: 0.5480 - val_accuracy: 0.9024\n",
            "Epoch 16/20\n",
            "375/375 [==============================] - 14s 37ms/step - loss: 0.0265 - accuracy: 0.9906 - val_loss: 0.3532 - val_accuracy: 0.9259\n",
            "Epoch 17/20\n",
            "375/375 [==============================] - 14s 37ms/step - loss: 0.0210 - accuracy: 0.9926 - val_loss: 0.3818 - val_accuracy: 0.9185\n",
            "Epoch 18/20\n",
            "375/375 [==============================] - 14s 37ms/step - loss: 0.0203 - accuracy: 0.9927 - val_loss: 0.4245 - val_accuracy: 0.9191\n",
            "Epoch 19/20\n",
            "375/375 [==============================] - 14s 37ms/step - loss: 0.0495 - accuracy: 0.9835 - val_loss: 0.3742 - val_accuracy: 0.9197\n",
            "Epoch 20/20\n",
            "375/375 [==============================] - 14s 37ms/step - loss: 0.0144 - accuracy: 0.9950 - val_loss: 0.4456 - val_accuracy: 0.9171\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.4558 - accuracy: 0.9166\n",
            "Test accuracy: 0.9165999889373779\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ResNet on CIFAR10"
      ],
      "metadata": {
        "id": "BCWN_-atfPOu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Load and preprocess the CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "def create_resnet_model(input_shape, num_classes):\n",
        "    base_model = ResNet50(include_top=False, input_shape=input_shape, pooling='avg')\n",
        "    base_model.trainable = False\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = base_model(inputs, training=False)\n",
        "    x = Flatten()(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "    model = Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "input_shape = (32, 32, 3)\n",
        "num_classes = 10\n",
        "model = create_resnet_model(input_shape, num_classes)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=64,\n",
        "                    validation_split=0.1,\n",
        "                    verbose=2)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(f'Test accuracy: {test_accuracy:.4f}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 957
        },
        "id": "GSL5m2LefReO",
        "outputId": "e811cde9-8e03-46a5-b484-aa9d205198eb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 5s 0us/step\n",
            "Epoch 1/20\n",
            "704/704 - 16s - loss: 2.1209 - accuracy: 0.2269 - val_loss: 2.0164 - val_accuracy: 0.2714 - 16s/epoch - 22ms/step\n",
            "Epoch 2/20\n",
            "704/704 - 10s - loss: 1.9570 - accuracy: 0.2969 - val_loss: 1.9081 - val_accuracy: 0.3302 - 10s/epoch - 14ms/step\n",
            "Epoch 3/20\n",
            "704/704 - 9s - loss: 1.8948 - accuracy: 0.3184 - val_loss: 1.8656 - val_accuracy: 0.3408 - 9s/epoch - 13ms/step\n",
            "Epoch 4/20\n",
            "704/704 - 9s - loss: 1.8666 - accuracy: 0.3336 - val_loss: 1.8757 - val_accuracy: 0.3156 - 9s/epoch - 13ms/step\n",
            "Epoch 5/20\n",
            "704/704 - 9s - loss: 1.8373 - accuracy: 0.3462 - val_loss: 1.8329 - val_accuracy: 0.3494 - 9s/epoch - 13ms/step\n",
            "Epoch 6/20\n",
            "704/704 - 8s - loss: 1.8128 - accuracy: 0.3547 - val_loss: 1.7989 - val_accuracy: 0.3606 - 8s/epoch - 12ms/step\n",
            "Epoch 7/20\n",
            "704/704 - 9s - loss: 1.7946 - accuracy: 0.3634 - val_loss: 1.8366 - val_accuracy: 0.3448 - 9s/epoch - 12ms/step\n",
            "Epoch 8/20\n",
            "704/704 - 8s - loss: 1.7814 - accuracy: 0.3677 - val_loss: 1.7637 - val_accuracy: 0.3740 - 8s/epoch - 12ms/step\n",
            "Epoch 9/20\n",
            "704/704 - 9s - loss: 1.7736 - accuracy: 0.3712 - val_loss: 1.8165 - val_accuracy: 0.3612 - 9s/epoch - 12ms/step\n",
            "Epoch 10/20\n",
            "704/704 - 9s - loss: 1.7655 - accuracy: 0.3740 - val_loss: 1.7315 - val_accuracy: 0.4056 - 9s/epoch - 13ms/step\n",
            "Epoch 11/20\n",
            "704/704 - 8s - loss: 1.7523 - accuracy: 0.3770 - val_loss: 1.7291 - val_accuracy: 0.3928 - 8s/epoch - 12ms/step\n",
            "Epoch 12/20\n",
            "704/704 - 9s - loss: 1.7425 - accuracy: 0.3836 - val_loss: 1.7147 - val_accuracy: 0.4048 - 9s/epoch - 13ms/step\n",
            "Epoch 13/20\n",
            "704/704 - 9s - loss: 1.7356 - accuracy: 0.3852 - val_loss: 1.7084 - val_accuracy: 0.4030 - 9s/epoch - 13ms/step\n",
            "Epoch 14/20\n",
            "704/704 - 9s - loss: 1.7277 - accuracy: 0.3886 - val_loss: 1.7004 - val_accuracy: 0.4114 - 9s/epoch - 13ms/step\n",
            "Epoch 15/20\n",
            "704/704 - 8s - loss: 1.7194 - accuracy: 0.3922 - val_loss: 1.7219 - val_accuracy: 0.3926 - 8s/epoch - 12ms/step\n",
            "Epoch 16/20\n",
            "704/704 - 9s - loss: 1.7130 - accuracy: 0.3938 - val_loss: 1.6996 - val_accuracy: 0.3954 - 9s/epoch - 13ms/step\n",
            "Epoch 17/20\n",
            "704/704 - 9s - loss: 1.7055 - accuracy: 0.3974 - val_loss: 1.6911 - val_accuracy: 0.4040 - 9s/epoch - 13ms/step\n",
            "Epoch 18/20\n",
            "704/704 - 9s - loss: 1.7026 - accuracy: 0.4009 - val_loss: 1.6952 - val_accuracy: 0.3952 - 9s/epoch - 13ms/step\n",
            "Epoch 19/20\n",
            "704/704 - 9s - loss: 1.6970 - accuracy: 0.4002 - val_loss: 1.6654 - val_accuracy: 0.4248 - 9s/epoch - 13ms/step\n",
            "Epoch 20/20\n",
            "704/704 - 10s - loss: 1.6924 - accuracy: 0.4009 - val_loss: 1.6994 - val_accuracy: 0.3948 - 10s/epoch - 14ms/step\n",
            "Test accuracy: 0.3869\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'base_model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-8fdd2e2dcb2e>\u001b[0m in \u001b[0;36m<cell line: 50>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m# Fine-tuning (optional)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m model.compile(optimizer=Adam(1e-5),\n\u001b[1;32m     52\u001b[0m               \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'base_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ResNet on CIFAR100"
      ],
      "metadata": {
        "id": "xBhV9j_nfR0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Load and preprocess the CIFAR-100 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "y_train = to_categorical(y_train, 100)\n",
        "y_test = to_categorical(y_test, 100)\n",
        "\n",
        "def create_resnet_model(input_shape, num_classes):\n",
        "    base_model = ResNet50(include_top=False, input_shape=input_shape, pooling='avg')\n",
        "    base_model.trainable = False\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = base_model(inputs, training=False)\n",
        "    x = Flatten()(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "    model = Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "input_shape = (32, 32, 3)\n",
        "num_classes = 100\n",
        "model = create_resnet_model(input_shape, num_classes)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=64,\n",
        "                    validation_split=0.1,\n",
        "                    verbose=2)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(f'Test accuracy: {test_accuracy:.4f}')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "1TeVXjHPfUPo",
        "outputId": "a456b6b2-a129-48b2-f278-985135be927f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "704/704 - 14s - loss: 4.5818 - accuracy: 0.0290 - val_loss: 4.4901 - val_accuracy: 0.0370 - 14s/epoch - 20ms/step\n",
            "Epoch 2/20\n",
            "704/704 - 9s - loss: 4.3770 - accuracy: 0.0529 - val_loss: 4.2870 - val_accuracy: 0.0672 - 9s/epoch - 13ms/step\n",
            "Epoch 3/20\n",
            "704/704 - 10s - loss: 4.2779 - accuracy: 0.0685 - val_loss: 4.2433 - val_accuracy: 0.0734 - 10s/epoch - 15ms/step\n",
            "Epoch 4/20\n",
            "704/704 - 9s - loss: 4.2067 - accuracy: 0.0790 - val_loss: 4.2418 - val_accuracy: 0.0718 - 9s/epoch - 13ms/step\n",
            "Epoch 5/20\n",
            "704/704 - 9s - loss: 4.1614 - accuracy: 0.0847 - val_loss: 4.1889 - val_accuracy: 0.0890 - 9s/epoch - 13ms/step\n",
            "Epoch 6/20\n",
            "704/704 - 9s - loss: 4.1266 - accuracy: 0.0905 - val_loss: 4.1557 - val_accuracy: 0.0830 - 9s/epoch - 12ms/step\n",
            "Epoch 7/20\n",
            "704/704 - 9s - loss: 4.0906 - accuracy: 0.0951 - val_loss: 4.1185 - val_accuracy: 0.0860 - 9s/epoch - 13ms/step\n",
            "Epoch 8/20\n",
            "704/704 - 9s - loss: 4.0594 - accuracy: 0.0983 - val_loss: 4.0431 - val_accuracy: 0.0972 - 9s/epoch - 12ms/step\n",
            "Epoch 9/20\n",
            "704/704 - 9s - loss: 4.0361 - accuracy: 0.1036 - val_loss: 4.1219 - val_accuracy: 0.0904 - 9s/epoch - 13ms/step\n",
            "Epoch 10/20\n",
            "704/704 - 9s - loss: 4.0152 - accuracy: 0.1066 - val_loss: 4.0919 - val_accuracy: 0.0988 - 9s/epoch - 12ms/step\n",
            "Epoch 11/20\n",
            "704/704 - 9s - loss: 3.9912 - accuracy: 0.1100 - val_loss: 4.0962 - val_accuracy: 0.1024 - 9s/epoch - 13ms/step\n",
            "Epoch 12/20\n",
            "704/704 - 9s - loss: 3.9765 - accuracy: 0.1118 - val_loss: 4.0653 - val_accuracy: 0.0960 - 9s/epoch - 13ms/step\n",
            "Epoch 13/20\n",
            "704/704 - 9s - loss: 3.9522 - accuracy: 0.1156 - val_loss: 4.0056 - val_accuracy: 0.1160 - 9s/epoch - 12ms/step\n",
            "Epoch 14/20\n",
            "704/704 - 9s - loss: 3.9348 - accuracy: 0.1186 - val_loss: 3.9858 - val_accuracy: 0.1052 - 9s/epoch - 12ms/step\n",
            "Epoch 15/20\n",
            "704/704 - 9s - loss: 3.9277 - accuracy: 0.1205 - val_loss: 4.0195 - val_accuracy: 0.1068 - 9s/epoch - 13ms/step\n",
            "Epoch 16/20\n",
            "704/704 - 9s - loss: 3.9124 - accuracy: 0.1225 - val_loss: 3.9551 - val_accuracy: 0.1134 - 9s/epoch - 13ms/step\n",
            "Epoch 17/20\n",
            "704/704 - 9s - loss: 3.8983 - accuracy: 0.1239 - val_loss: 3.9776 - val_accuracy: 0.1150 - 9s/epoch - 13ms/step\n",
            "Epoch 18/20\n",
            "704/704 - 9s - loss: 3.8830 - accuracy: 0.1266 - val_loss: 3.9820 - val_accuracy: 0.1152 - 9s/epoch - 13ms/step\n",
            "Epoch 19/20\n",
            "704/704 - 8s - loss: 3.8677 - accuracy: 0.1284 - val_loss: 3.9198 - val_accuracy: 0.1208 - 8s/epoch - 12ms/step\n",
            "Epoch 20/20\n",
            "704/704 - 8s - loss: 3.8576 - accuracy: 0.1319 - val_loss: 3.9610 - val_accuracy: 0.1128 - 8s/epoch - 12ms/step\n",
            "Test accuracy: 0.1140\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DenseNet on MNIST"
      ],
      "metadata": {
        "id": "ueAmFhVyfVGd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load and preprocess the MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "# Define a Dense Block\n",
        "def dense_block(x, blocks, name):\n",
        "    for i in range(blocks):\n",
        "        x = conv_block(x, 32, name=name + '_block' + str(i + 1))\n",
        "    return x\n",
        "\n",
        "# Define a Convolution Block\n",
        "def conv_block(x, growth_rate, name):\n",
        "    x1 = layers.BatchNormalization(name=name + '_bn')(x)\n",
        "    x1 = layers.Activation('relu', name=name + '_relu')(x1)\n",
        "    x1 = layers.Conv2D(4 * growth_rate, 1, use_bias=False, name=name + '_conv1')(x1)\n",
        "    x1 = layers.BatchNormalization(name=name + '_bn2')(x1)\n",
        "    x1 = layers.Activation('relu', name=name + '_relu2')(x1)\n",
        "    x1 = layers.Conv2D(growth_rate, 3, padding='same', use_bias=False, name=name + '_conv2')(x1)\n",
        "    x = layers.Concatenate(name=name + '_concat')([x, x1])\n",
        "    return x\n",
        "\n",
        "# Define a Transition Layer\n",
        "def transition_block(x, reduction, name):\n",
        "    x = layers.BatchNormalization(name=name + '_bn')(x)\n",
        "    x = layers.Activation('relu', name=name + '_relu')(x)\n",
        "    x = layers.Conv2D(int(tf.keras.backend.int_shape(x)[-1] * reduction), 1, use_bias=False, name=name + '_conv')(x)\n",
        "    x = layers.AveragePooling2D(2, strides=2, name=name + '_pool')(x)\n",
        "    return x\n",
        "\n",
        "# Define the DenseNet model\n",
        "def DenseNet(input_shape, num_classes):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    x = layers.Conv2D(64, 3, padding='same', use_bias=False, name='conv1/conv')(inputs)\n",
        "    x = layers.BatchNormalization(name='conv1/bn')(x)\n",
        "    x = layers.Activation('relu', name='conv1/relu')(x)\n",
        "    x = layers.MaxPooling2D(2, strides=2, padding='same', name='pool1')(x)\n",
        "\n",
        "    x = dense_block(x, 6, name='conv2')\n",
        "    x = transition_block(x, 0.5, name='pool2')\n",
        "\n",
        "    x = dense_block(x, 12, name='conv3')\n",
        "    x = transition_block(x, 0.5, name='pool3')\n",
        "\n",
        "    x = dense_block(x, 24, name='conv4')\n",
        "\n",
        "    x = layers.BatchNormalization(name='bn')(x)\n",
        "    x = layers.Activation('relu', name='relu')(x)\n",
        "    x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
        "    x = layers.Dense(num_classes, activation='softmax', name='fc')(x)\n",
        "\n",
        "    model = models.Model(inputs, x, name='densenet')\n",
        "    return model\n",
        "\n",
        "# Build and compile the model\n",
        "model = DenseNet(input_shape=(28, 28, 1), num_classes=10)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_images, train_labels, epochs=10, batch_size=64, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "feCd4KfGfXlv",
        "outputId": "69e845f2-50fe-45a8-ac1e-926754526325"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "750/750 [==============================] - 97s 68ms/step - loss: 0.0978 - accuracy: 0.9705 - val_loss: 0.0545 - val_accuracy: 0.9821\n",
            "Epoch 2/10\n",
            "750/750 [==============================] - 51s 67ms/step - loss: 0.0422 - accuracy: 0.9872 - val_loss: 0.0435 - val_accuracy: 0.9883\n",
            "Epoch 3/10\n",
            "750/750 [==============================] - 50s 66ms/step - loss: 0.0318 - accuracy: 0.9903 - val_loss: 0.0773 - val_accuracy: 0.9798\n",
            "Epoch 4/10\n",
            "750/750 [==============================] - 48s 64ms/step - loss: 0.0283 - accuracy: 0.9910 - val_loss: 0.0712 - val_accuracy: 0.9784\n",
            "Epoch 5/10\n",
            "750/750 [==============================] - 51s 68ms/step - loss: 0.0220 - accuracy: 0.9928 - val_loss: 0.0368 - val_accuracy: 0.9900\n",
            "Epoch 6/10\n",
            "750/750 [==============================] - 52s 69ms/step - loss: 0.0223 - accuracy: 0.9930 - val_loss: 0.0788 - val_accuracy: 0.9778\n",
            "Epoch 7/10\n",
            "750/750 [==============================] - 51s 68ms/step - loss: 0.0189 - accuracy: 0.9941 - val_loss: 0.0519 - val_accuracy: 0.9862\n",
            "Epoch 8/10\n",
            "750/750 [==============================] - 50s 67ms/step - loss: 0.0168 - accuracy: 0.9948 - val_loss: 0.0411 - val_accuracy: 0.9887\n",
            "Epoch 9/10\n",
            "750/750 [==============================] - 50s 67ms/step - loss: 0.0165 - accuracy: 0.9950 - val_loss: 0.0369 - val_accuracy: 0.9905\n",
            "Epoch 10/10\n",
            "750/750 [==============================] - 50s 67ms/step - loss: 0.0135 - accuracy: 0.9956 - val_loss: 0.0302 - val_accuracy: 0.9924\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.0267 - accuracy: 0.9918\n",
            "Test accuracy: 0.9918000102043152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DenseNet on Fashion-MNIST\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IOesOe3IfYKT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load and preprocess the Fashion-MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "# Define a Dense Block\n",
        "def dense_block(x, blocks, name):\n",
        "    for i in range(blocks):\n",
        "        x = conv_block(x, 32, name=name + '_block' + str(i + 1))\n",
        "    return x\n",
        "\n",
        "# Define a Convolution Block\n",
        "def conv_block(x, growth_rate, name):\n",
        "    x1 = layers.BatchNormalization(name=name + '_bn')(x)\n",
        "    x1 = layers.Activation('relu', name=name + '_relu')(x1)\n",
        "    x1 = layers.Conv2D(4 * growth_rate, 1, use_bias=False, name=name + '_conv1')(x1)\n",
        "    x1 = layers.BatchNormalization(name=name + '_bn2')(x1)\n",
        "    x1 = layers.Activation('relu', name=name + '_relu2')(x1)\n",
        "    x1 = layers.Conv2D(growth_rate, 3, padding='same', use_bias=False, name=name + '_conv2')(x1)\n",
        "    x = layers.Concatenate(name=name + '_concat')([x, x1])\n",
        "    return x\n",
        "\n",
        "# Define a Transition Layer\n",
        "def transition_block(x, reduction, name):\n",
        "    x = layers.BatchNormalization(name=name + '_bn')(x)\n",
        "    x = layers.Activation('relu', name=name + '_relu')(x)\n",
        "    x = layers.Conv2D(int(tf.keras.backend.int_shape(x)[-1] * reduction), 1, use_bias=False, name=name + '_conv')(x)\n",
        "    x = layers.AveragePooling2D(2, strides=2, name=name + '_pool')(x)\n",
        "    return x\n",
        "\n",
        "# Define the DenseNet model\n",
        "def DenseNet(input_shape, num_classes):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    x = layers.Conv2D(64, 3, padding='same', use_bias=False, name='conv1/conv')(inputs)\n",
        "    x = layers.BatchNormalization(name='conv1/bn')(x)\n",
        "    x = layers.Activation('relu', name='conv1/relu')(x)\n",
        "    x = layers.MaxPooling2D(2, strides=2, padding='same', name='pool1')(x)\n",
        "\n",
        "    x = dense_block(x, 6, name='conv2')\n",
        "    x = transition_block(x, 0.5, name='pool2')\n",
        "\n",
        "    x = dense_block(x, 12, name='conv3')\n",
        "    x = transition_block(x, 0.5, name='pool3')\n",
        "\n",
        "    x = dense_block(x, 24, name='conv4')\n",
        "\n",
        "    x = layers.BatchNormalization(name='bn')(x)\n",
        "    x = layers.Activation('relu', name='relu')(x)\n",
        "    x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
        "    x = layers.Dense(num_classes, activation='softmax', name='fc')(x)\n",
        "\n",
        "    model = models.Model(inputs, x, name='densenet')\n",
        "    return model\n",
        "\n",
        "# Build and compile the model\n",
        "model = DenseNet(input_shape=(28, 28, 1), num_classes=10)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_images, train_labels, epochs=10, batch_size=64, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ec5on8vwfbW7",
        "outputId": "cf148468-842c-46b2-8fa3-6c259aca596c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "750/750 [==============================] - 85s 66ms/step - loss: 0.3949 - accuracy: 0.8544 - val_loss: 0.6967 - val_accuracy: 0.7907\n",
            "Epoch 2/10\n",
            "750/750 [==============================] - 50s 67ms/step - loss: 0.2580 - accuracy: 0.9060 - val_loss: 0.3349 - val_accuracy: 0.8727\n",
            "Epoch 3/10\n",
            "750/750 [==============================] - 47s 63ms/step - loss: 0.2175 - accuracy: 0.9206 - val_loss: 0.2542 - val_accuracy: 0.9062\n",
            "Epoch 4/10\n",
            "750/750 [==============================] - 50s 67ms/step - loss: 0.1933 - accuracy: 0.9290 - val_loss: 0.4017 - val_accuracy: 0.8683\n",
            "Epoch 5/10\n",
            "750/750 [==============================] - 47s 62ms/step - loss: 0.1744 - accuracy: 0.9362 - val_loss: 0.2197 - val_accuracy: 0.9212\n",
            "Epoch 6/10\n",
            "750/750 [==============================] - 49s 66ms/step - loss: 0.1532 - accuracy: 0.9445 - val_loss: 0.2476 - val_accuracy: 0.9115\n",
            "Epoch 7/10\n",
            "750/750 [==============================] - 49s 66ms/step - loss: 0.1396 - accuracy: 0.9479 - val_loss: 0.2136 - val_accuracy: 0.9272\n",
            "Epoch 8/10\n",
            "750/750 [==============================] - 48s 64ms/step - loss: 0.1222 - accuracy: 0.9551 - val_loss: 0.2379 - val_accuracy: 0.9182\n",
            "Epoch 9/10\n",
            "750/750 [==============================] - 48s 63ms/step - loss: 0.1079 - accuracy: 0.9591 - val_loss: 0.2388 - val_accuracy: 0.9199\n",
            "Epoch 10/10\n",
            "750/750 [==============================] - 48s 65ms/step - loss: 0.0914 - accuracy: 0.9659 - val_loss: 0.2795 - val_accuracy: 0.9227\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.3176 - accuracy: 0.9197\n",
            "Test accuracy: 0.919700026512146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DenseNet on CIFAR10"
      ],
      "metadata": {
        "id": "exRf_kuxfbvh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load and preprocess the CIFAR-10 dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "train_images = train_images.astype('float32') / 255\n",
        "test_images = test_images.astype('float32') / 255\n",
        "train_labels = to_categorical(train_labels, 10)\n",
        "test_labels = to_categorical(test_labels, 10)\n",
        "\n",
        "# Define a Dense Block\n",
        "def dense_block(x, blocks, name):\n",
        "    for i in range(blocks):\n",
        "        x = conv_block(x, 32, name=name + '_block' + str(i + 1))\n",
        "    return x\n",
        "\n",
        "# Define a Convolution Block\n",
        "def conv_block(x, growth_rate, name):\n",
        "    x1 = layers.BatchNormalization(name=name + '_bn')(x)\n",
        "    x1 = layers.Activation('relu', name=name + '_relu')(x1)\n",
        "    x1 = layers.Conv2D(4 * growth_rate, 1, use_bias=False, name=name + '_conv1')(x1)\n",
        "    x1 = layers.BatchNormalization(name=name + '_bn2')(x1)\n",
        "    x1 = layers.Activation('relu', name=name + '_relu2')(x1)\n",
        "    x1 = layers.Conv2D(growth_rate, 3, padding='same', use_bias=False, name=name + '_conv2')(x1)\n",
        "    x = layers.Concatenate(name=name + '_concat')([x, x1])\n",
        "    return x\n",
        "\n",
        "# Define a Transition Layer\n",
        "def transition_block(x, reduction, name):\n",
        "    x = layers.BatchNormalization(name=name + '_bn')(x)\n",
        "    x = layers.Activation('relu', name=name + '_relu')(x)\n",
        "    x = layers.Conv2D(int(tf.keras.backend.int_shape(x)[-1] * reduction), 1, use_bias=False, name=name + '_conv')(x)\n",
        "    x = layers.AveragePooling2D(2, strides=2, name=name + '_pool')(x)\n",
        "    return x\n",
        "\n",
        "# Define the DenseNet model\n",
        "def DenseNet(input_shape, num_classes):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    x = layers.Conv2D(64, 3, padding='same', use_bias=False, name='conv1/conv')(inputs)\n",
        "    x = layers.BatchNormalization(name='conv1/bn')(x)\n",
        "    x = layers.Activation('relu', name='conv1/relu')(x)\n",
        "    x = layers.MaxPooling2D(2, strides=2, padding='same', name='pool1')(x)\n",
        "\n",
        "    x = dense_block(x, 6, name='conv2')\n",
        "    x = transition_block(x, 0.5, name='pool2')\n",
        "\n",
        "    x = dense_block(x, 12, name='conv3')\n",
        "    x = transition_block(x, 0.5, name='pool3')\n",
        "\n",
        "    x = dense_block(x, 24, name='conv4')\n",
        "\n",
        "    x = layers.BatchNormalization(name='bn')(x)\n",
        "    x = layers.Activation('relu', name='relu')(x)\n",
        "    x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
        "    x = layers.Dense(num_classes, activation='softmax', name='fc')(x)\n",
        "\n",
        "    model = models.Model(inputs, x, name='densenet')\n",
        "    return model\n",
        "\n",
        "# Build and compile the model\n",
        "model = DenseNet(input_shape=(32, 32, 3), num_classes=10)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_images, train_labels, epochs=10, batch_size=64, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "TWb-jGkqfhJu",
        "outputId": "77507c65-1b44-4a4a-cf54-614562552255"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 89s 76ms/step - loss: 1.2472 - accuracy: 0.5511 - val_loss: 1.2586 - val_accuracy: 0.5697\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 44s 70ms/step - loss: 0.7782 - accuracy: 0.7283 - val_loss: 1.0828 - val_accuracy: 0.6396\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 44s 71ms/step - loss: 0.6059 - accuracy: 0.7896 - val_loss: 1.4614 - val_accuracy: 0.6018\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 47s 76ms/step - loss: 0.5009 - accuracy: 0.8255 - val_loss: 0.8131 - val_accuracy: 0.7405\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 46s 74ms/step - loss: 0.4070 - accuracy: 0.8596 - val_loss: 0.8145 - val_accuracy: 0.7409\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 47s 75ms/step - loss: 0.3338 - accuracy: 0.8848 - val_loss: 0.8627 - val_accuracy: 0.7451\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 47s 74ms/step - loss: 0.2744 - accuracy: 0.9024 - val_loss: 0.7612 - val_accuracy: 0.7829\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 46s 74ms/step - loss: 0.2187 - accuracy: 0.9232 - val_loss: 1.2470 - val_accuracy: 0.6917\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 43s 69ms/step - loss: 0.1743 - accuracy: 0.9387 - val_loss: 1.2014 - val_accuracy: 0.7027\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 45s 72ms/step - loss: 0.1467 - accuracy: 0.9491 - val_loss: 0.8116 - val_accuracy: 0.7812\n",
            "313/313 [==============================] - 5s 12ms/step - loss: 0.8374 - accuracy: 0.7745\n",
            "Test accuracy: 0.7745000123977661\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DenseNet on CIFAR100"
      ],
      "metadata": {
        "id": "3CmdhKibfhfO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load and preprocess the CIFAR-100 dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar100.load_data(label_mode='fine')\n",
        "train_images = train_images.astype('float32') / 255\n",
        "test_images = test_images.astype('float32') / 255\n",
        "train_labels = to_categorical(train_labels, 100)\n",
        "test_labels = to_categorical(test_labels, 100)\n",
        "\n",
        "# Define a Dense Block\n",
        "def dense_block(x, blocks, name):\n",
        "    for i in range(blocks):\n",
        "        x = conv_block(x, 32, name=name + '_block' + str(i + 1))\n",
        "    return x\n",
        "\n",
        "# Define a Convolution Block\n",
        "def conv_block(x, growth_rate, name):\n",
        "    x1 = layers.BatchNormalization(name=name + '_bn')(x)\n",
        "    x1 = layers.Activation('relu', name=name + '_relu')(x1)\n",
        "    x1 = layers.Conv2D(4 * growth_rate, 1, use_bias=False, name=name + '_conv1')(x1)\n",
        "    x1 = layers.BatchNormalization(name=name + '_bn2')(x1)\n",
        "    x1 = layers.Activation('relu', name=name + '_relu2')(x1)\n",
        "    x1 = layers.Conv2D(growth_rate, 3, padding='same', use_bias=False, name=name + '_conv2')(x1)\n",
        "    x = layers.Concatenate(name=name + '_concat')([x, x1])\n",
        "    return x\n",
        "\n",
        "# Define a Transition Layer\n",
        "def transition_block(x, reduction, name):\n",
        "    x = layers.BatchNormalization(name=name + '_bn')(x)\n",
        "    x = layers.Activation('relu', name=name + '_relu')(x)\n",
        "    x = layers.Conv2D(int(tf.keras.backend.int_shape(x)[-1] * reduction), 1, use_bias=False, name=name + '_conv')(x)\n",
        "    x = layers.AveragePooling2D(2, strides=2, name=name + '_pool')(x)\n",
        "    return x\n",
        "\n",
        "# Define the DenseNet model\n",
        "def DenseNet(input_shape, num_classes):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    x = layers.Conv2D(64, 3, padding='same', use_bias=False, name='conv1/conv')(inputs)\n",
        "    x = layers.BatchNormalization(name='conv1/bn')(x)\n",
        "    x = layers.Activation('relu', name='conv1/relu')(x)\n",
        "    x = layers.MaxPooling2D(2, strides=2, padding='same', name='pool1')(x)\n",
        "\n",
        "    x = dense_block(x, 6, name='conv2')\n",
        "    x = transition_block(x, 0.5, name='pool2')\n",
        "\n",
        "    x = dense_block(x, 12, name='conv3')\n",
        "    x = transition_block(x, 0.5, name='pool3')\n",
        "\n",
        "    x = dense_block(x, 24, name='conv4')\n",
        "\n",
        "    x = layers.BatchNormalization(name='bn')(x)\n",
        "    x = layers.Activation('relu', name='relu')(x)\n",
        "    x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
        "    x = layers.Dense(num_classes, activation='softmax', name='fc')(x)\n",
        "\n",
        "    model = models.Model(inputs, x, name='densenet')\n",
        "    return model\n",
        "\n",
        "# Build and compile the model\n",
        "model = DenseNet(input_shape=(32, 32, 3), num_classes=100)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_images, train_labels, epochs=10, batch_size=64, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "qq2CAA0rfkAb",
        "outputId": "2621764d-62e7-4394-cc0a-9c082d16c19b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 83s 73ms/step - loss: 3.5060 - accuracy: 0.1663 - val_loss: 3.1992 - val_accuracy: 0.2119\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 47s 75ms/step - loss: 2.5790 - accuracy: 0.3297 - val_loss: 2.4894 - val_accuracy: 0.3488\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 46s 74ms/step - loss: 2.0966 - accuracy: 0.4327 - val_loss: 2.4970 - val_accuracy: 0.3684\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 47s 75ms/step - loss: 1.7676 - accuracy: 0.5068 - val_loss: 2.3224 - val_accuracy: 0.4048\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 45s 71ms/step - loss: 1.5040 - accuracy: 0.5714 - val_loss: 2.2671 - val_accuracy: 0.4285\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 47s 75ms/step - loss: 1.2736 - accuracy: 0.6303 - val_loss: 2.8147 - val_accuracy: 0.3801\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 46s 74ms/step - loss: 1.0737 - accuracy: 0.6835 - val_loss: 2.3241 - val_accuracy: 0.4449\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 45s 72ms/step - loss: 0.8876 - accuracy: 0.7301 - val_loss: 2.0321 - val_accuracy: 0.4967\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 46s 74ms/step - loss: 0.7141 - accuracy: 0.7800 - val_loss: 2.6736 - val_accuracy: 0.4169\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 46s 73ms/step - loss: 0.5535 - accuracy: 0.8245 - val_loss: 2.3594 - val_accuracy: 0.4954\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 2.3145 - accuracy: 0.5033\n",
            "Test accuracy: 0.5033000111579895\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparison between four CNN Architectures"
      ],
      "metadata": {
        "id": "dKgOjhUn2Xsn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist, fashion_mnist, cifar10, cifar100\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Activation, AveragePooling2D, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.applications import VGG16, ResNet50, DenseNet121\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, array_to_img\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "# Helper function to preprocess datasets\n",
        "def preprocess_data(dataset, num_channels, target_size):\n",
        "    (train_images, train_labels), (test_images, test_labels) = dataset.load_data()\n",
        "    train_images = train_images.astype('float32') / 255\n",
        "    test_images = test_images.astype('float32') / 255\n",
        "    train_labels = to_categorical(train_labels)\n",
        "    test_labels = to_categorical(test_labels)\n",
        "\n",
        "    # Reshape images to have the required number of channels\n",
        "    if num_channels == 1:  # Grayscale images\n",
        "        train_images = np.expand_dims(train_images, axis=-1)\n",
        "        test_images = np.expand_dims(test_images, axis=-1)\n",
        "\n",
        "        # Convert grayscale to RGB by duplicating the single channel three times\n",
        "        train_images = np.repeat(train_images, 3, axis=-1)\n",
        "        test_images = np.repeat(test_images, 3, axis=-1)\n",
        "\n",
        "    # Resize images to the target size\n",
        "    train_images = np.array([img_to_array(array_to_img(image, scale=False).resize(target_size)) for image in train_images])\n",
        "    test_images = np.array([img_to_array(array_to_img(image, scale=False).resize(target_size)) for image in test_images])\n",
        "\n",
        "    return (train_images, train_labels), (test_images, test_labels)\n",
        "\n",
        "# Define the LeNet model architecture\n",
        "def LeNet(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        Conv2D(6, kernel_size=(5, 5), activation='relu', input_shape=input_shape),\n",
        "        AveragePooling2D(),\n",
        "        Conv2D(16, kernel_size=(5, 5), activation='relu'),\n",
        "        AveragePooling2D(),\n",
        "        Flatten(),\n",
        "        Dense(120, activation='relu'),\n",
        "        Dense(84, activation='relu'),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Load datasets\n",
        "datasets = {\n",
        "    \"MNIST\": (mnist, 1, (32, 32)),\n",
        "    \"Fashion MNIST\": (fashion_mnist, 1, (32, 32)),\n",
        "    \"CIFAR-10\": (cifar10, 3, (32, 32)),\n",
        "    \"CIFAR-100\": (cifar100, 3, (32, 32))\n",
        "}\n",
        "\n",
        "# Define architectures\n",
        "architectures = {\n",
        "    \"LeNet\": LeNet,\n",
        "    \"VGG16\": lambda input_shape, num_classes: Sequential([VGG16(include_top=False, input_shape=input_shape, pooling='avg'), Dense(num_classes, activation='softmax')]),\n",
        "    \"ResNet50\": lambda input_shape, num_classes: Sequential([ResNet50(include_top=False, input_shape=input_shape, pooling='avg'), Dense(num_classes, activation='softmax')]),\n",
        "    \"DenseNet121\": lambda input_shape, num_classes: Sequential([DenseNet121(include_top=False, input_shape=input_shape, pooling='avg'), Dense(num_classes, activation='softmax')])\n",
        "}\n",
        "\n",
        "# Training and evaluation parameters\n",
        "batch_size = 128\n",
        "epochs = 10\n",
        "results = {}\n",
        "\n",
        "# Train and evaluate models\n",
        "for dataset_name, (dataset, num_channels, target_size) in datasets.items():\n",
        "    (train_images, train_labels), (test_images, test_labels) = preprocess_data(dataset, num_channels, target_size)\n",
        "    input_shape = train_images.shape[1:]\n",
        "    num_classes = train_labels.shape[1]\n",
        "\n",
        "    results[dataset_name] = {}\n",
        "\n",
        "    for arch_name, arch_func in architectures.items():\n",
        "        model = arch_func(input_shape, num_classes)\n",
        "        model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['accuracy'])\n",
        "\n",
        "        history = model.fit(train_images, train_labels, epochs=epochs, batch_size=batch_size, validation_split=0.2)\n",
        "\n",
        "        test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "        print(f'{arch_name} on {dataset_name} - Test accuracy: {test_acc}')\n",
        "\n",
        "        results[dataset_name][arch_name] = {\n",
        "            'test_loss': test_loss,\n",
        "            'test_accuracy': test_acc,\n",
        "            'history': history.history\n",
        "        }\n",
        "\n",
        "# Save the results to a JSON file\n",
        "with open('model_comparison_results.json', 'w') as f:\n",
        "    json.dump(results, f)\n",
        "\n",
        "# Visualize the results\n",
        "for dataset_name in results:\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    for arch_name in results[dataset_name]:\n",
        "        plt.plot(results[dataset_name][arch_name]['history']['val_accuracy'], label=f'{arch_name} on {dataset_name}')\n",
        "    plt.title(f'Model Validation Accuracy on {dataset_name}')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Validation Accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 981
        },
        "id": "YP3lWOUt2c8J",
        "outputId": "8d31b527-0870-49ee-c3c5-d092b788d066"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "375/375 [==============================] - 4s 7ms/step - loss: 1.8766 - accuracy: 0.3339 - val_loss: 1.6998 - val_accuracy: 0.3925\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.6753 - accuracy: 0.3966 - val_loss: 1.6434 - val_accuracy: 0.4085\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.6345 - accuracy: 0.4087 - val_loss: 1.6363 - val_accuracy: 0.4058\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.6127 - accuracy: 0.4182 - val_loss: 1.6057 - val_accuracy: 0.4181\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.5945 - accuracy: 0.4223 - val_loss: 1.5980 - val_accuracy: 0.4201\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.5819 - accuracy: 0.4280 - val_loss: 1.5879 - val_accuracy: 0.4207\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.5733 - accuracy: 0.4311 - val_loss: 1.5913 - val_accuracy: 0.4223\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.5639 - accuracy: 0.4323 - val_loss: 1.5913 - val_accuracy: 0.4190\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.5565 - accuracy: 0.4345 - val_loss: 1.5822 - val_accuracy: 0.4245\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.5478 - accuracy: 0.4379 - val_loss: 1.5987 - val_accuracy: 0.4219\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 1.6009 - accuracy: 0.4272\n",
            "LeNet on MNIST - Test accuracy: 0.42719998955726624\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 3s 0us/step\n",
            "Epoch 1/10\n",
            "375/375 [==============================] - 26s 58ms/step - loss: 2.3104 - accuracy: 0.1071 - val_loss: 2.3073 - val_accuracy: 0.1060\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 20s 53ms/step - loss: 2.3069 - accuracy: 0.1054 - val_loss: 2.3098 - val_accuracy: 0.1060\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 20s 52ms/step - loss: 2.3072 - accuracy: 0.1053 - val_loss: 2.3115 - val_accuracy: 0.1060\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 19s 52ms/step - loss: 2.3063 - accuracy: 0.1051 - val_loss: 2.3051 - val_accuracy: 0.1060\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 20s 52ms/step - loss: 2.3061 - accuracy: 0.1064 - val_loss: 2.3064 - val_accuracy: 0.0975\n",
            "Epoch 6/10\n",
            "123/375 [========>.....................] - ETA: 13s - loss: 2.3055 - accuracy: 0.1064"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-ebb53171c389>\u001b[0m in \u001b[0;36m<cell line: 73>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCategoricalCrossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist, fashion_mnist, cifar10, cifar100\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Activation, AveragePooling2D, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.applications import VGG16, ResNet50, DenseNet121\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, array_to_img\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "import json\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Helper function to preprocess datasets\n",
        "def preprocess_data(dataset, num_channels, target_size):\n",
        "    (train_images, train_labels), (test_images, test_labels) = dataset.load_data()\n",
        "    train_images = train_images.astype('float32') / 255\n",
        "    test_images = test_images.astype('float32') / 255\n",
        "    train_labels = to_categorical(train_labels)\n",
        "    test_labels = to_categorical(test_labels)\n",
        "\n",
        "    # Reshape images to have the required number of channels\n",
        "    if num_channels == 1:  # Grayscale images\n",
        "        train_images = np.expand_dims(train_images, axis=-1)\n",
        "        test_images = np.expand_dims(test_images, axis=-1)\n",
        "\n",
        "        # Convert grayscale to RGB by duplicating the single channel three times\n",
        "        train_images = np.repeat(train_images, 3, axis=-1)\n",
        "        test_images = np.repeat(test_images, 3, axis=-1)\n",
        "\n",
        "    # Resize images to the target size\n",
        "    train_images = np.array([img_to_array(array_to_img(image, scale=False).resize(target_size)) for image in train_images])\n",
        "    test_images = np.array([img_to_array(array_to_img(image, scale=False).resize(target_size)) for image in test_images])\n",
        "\n",
        "    return (train_images, train_labels), (test_images, test_labels)\n",
        "\n",
        "# Define the LeNet model architecture\n",
        "def LeNet(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        Conv2D(6, kernel_size=(5, 5), activation='relu', input_shape=input_shape),\n",
        "        AveragePooling2D(),\n",
        "        Conv2D(16, kernel_size=(5, 5), activation='relu'),\n",
        "        AveragePooling2D(),\n",
        "        Flatten(),\n",
        "        Dense(120, activation='relu'),\n",
        "        Dense(84, activation='relu'),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Load datasets\n",
        "datasets = {\n",
        "    \"MNIST\": (mnist, 1, (32, 32)),\n",
        "    \"Fashion MNIST\": (fashion_mnist, 1, (32, 32)),\n",
        "    \"CIFAR-10\": (cifar10, 3, (32, 32)),\n",
        "    \"CIFAR-100\": (cifar100, 3, (32, 32))\n",
        "}\n",
        "\n",
        "# Define architectures\n",
        "architectures = {\n",
        "    \"LeNet\": LeNet,\n",
        "    \"VGG16\": lambda input_shape, num_classes: Sequential([VGG16(include_top=False, input_shape=input_shape, pooling='avg'), Dense(num_classes, activation='softmax')]),\n",
        "    \"ResNet50\": lambda input_shape, num_classes: Sequential([ResNet50(include_top=False, input_shape=input_shape, pooling='avg'), Dense(num_classes, activation='softmax')]),\n",
        "    \"DenseNet121\": lambda input_shape, num_classes: Sequential([DenseNet121(include_top=False, input_shape=input_shape, pooling='avg'), Dense(num_classes, activation='softmax')])\n",
        "}\n",
        "\n",
        "# Training and evaluation parameters\n",
        "batch_size = 128\n",
        "epochs = 10\n",
        "results = []\n",
        "\n",
        "# Train and evaluate models\n",
        "for dataset_name, (dataset, num_channels, target_size) in datasets.items():\n",
        "    (train_images, train_labels), (test_images, test_labels) = preprocess_data(dataset, num_channels, target_size)\n",
        "    input_shape = train_images.shape[1:]\n",
        "    num_classes = train_labels.shape[1]\n",
        "\n",
        "    for arch_name, arch_func in architectures.items():\n",
        "        model = arch_func(input_shape, num_classes)\n",
        "        model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['accuracy'])\n",
        "\n",
        "        history = model.fit(train_images, train_labels, epochs=epochs, batch_size=batch_size, validation_split=0.2)\n",
        "\n",
        "        test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "        print(f'{arch_name} on {dataset_name} - Test accuracy: {test_acc}')\n",
        "\n",
        "        # Calculate additional metrics\n",
        "        predictions = model.predict(test_images)\n",
        "        y_true = np.argmax(test_labels, axis=1)\n",
        "        y_pred = np.argmax(predictions, axis=1)\n",
        "\n",
        "        report = classification_report(y_true, y_pred, output_dict=True, zero_division=0)\n",
        "        precision = report['weighted avg']['precision']\n",
        "        recall = report['weighted avg']['recall']\n",
        "        f1_score = report['weighted avg']['f1-score']\n",
        "        true_positives = sum(np.diag(np.array([report[str(i)][\"support\"] for i in range(num_classes)])))\n",
        "\n",
        "        results.append({\n",
        "            'Dataset': dataset_name,\n",
        "            'Model': arch_name,\n",
        "            'Test Accuracy': test_acc,\n",
        "            'Precision': precision,\n",
        "            'Recall': recall,\n",
        "            'F1 Score': f1_score,\n",
        "            'True Positives': true_positives\n",
        "        })\n",
        "\n",
        "# Convert results to DataFrame\n",
        "df = pd.DataFrame(results)\n",
        "print(df)\n",
        "\n",
        "# Save the results to a CSV file\n",
        "df.to_csv('model_comparison_results.csv', index=False)\n",
        "\n",
        "# Display the results in a formatted table\n",
        "print(df.to_markdown(index=False))\n",
        "\n",
        "# Visualize the results\n",
        "for dataset_name in datasets.keys():\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    dataset_results = df[df['Dataset'] == dataset_name]\n",
        "    for index, row in dataset_results.iterrows():\n",
        "        plt.plot(row['Test Accuracy'], label=f'{row[\"Model\"]} on {dataset_name}')\n",
        "    plt.title(f'Model Validation Accuracy on {dataset_name}')\n",
        "    plt.xlabel('Models')\n",
        "    plt.ylabel('Validation Accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5OJ0c4S4ap6",
        "outputId": "65a0b61e-1b1f-4e3b-f664-27ed0b4e864d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "375/375 [==============================] - 7s 6ms/step - loss: 1.8918 - accuracy: 0.3322 - val_loss: 1.7114 - val_accuracy: 0.3916\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.6837 - accuracy: 0.3960 - val_loss: 1.6519 - val_accuracy: 0.4047\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.6403 - accuracy: 0.4079 - val_loss: 1.6296 - val_accuracy: 0.4094\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.6165 - accuracy: 0.4142 - val_loss: 1.6088 - val_accuracy: 0.4197\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.6021 - accuracy: 0.4187 - val_loss: 1.6048 - val_accuracy: 0.4188\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.5880 - accuracy: 0.4242 - val_loss: 1.5936 - val_accuracy: 0.4232\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.5766 - accuracy: 0.4277 - val_loss: 1.5943 - val_accuracy: 0.4182\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.5676 - accuracy: 0.4307 - val_loss: 1.5903 - val_accuracy: 0.4247\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.5599 - accuracy: 0.4335 - val_loss: 1.5932 - val_accuracy: 0.4237\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.5520 - accuracy: 0.4360 - val_loss: 1.5839 - val_accuracy: 0.4257\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.5863 - accuracy: 0.4316\n",
            "LeNet on MNIST - Test accuracy: 0.43160000443458557\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "Epoch 1/10\n",
            "375/375 [==============================] - 30s 57ms/step - loss: 2.3164 - accuracy: 0.1046 - val_loss: 2.3059 - val_accuracy: 0.1035\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 19s 51ms/step - loss: 2.3070 - accuracy: 0.1074 - val_loss: 2.3051 - val_accuracy: 0.1081\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 21s 55ms/step - loss: 2.3067 - accuracy: 0.1071 - val_loss: 2.3040 - val_accuracy: 0.1060\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 19s 52ms/step - loss: 2.3064 - accuracy: 0.1063 - val_loss: 2.3108 - val_accuracy: 0.0956\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 21s 56ms/step - loss: 2.3068 - accuracy: 0.1044 - val_loss: 2.3084 - val_accuracy: 0.1060\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 20s 52ms/step - loss: 2.3060 - accuracy: 0.1057 - val_loss: 2.3103 - val_accuracy: 0.1060\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 20s 53ms/step - loss: 2.3050 - accuracy: 0.1069 - val_loss: 2.3087 - val_accuracy: 0.0997\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 20s 52ms/step - loss: 2.3062 - accuracy: 0.1035 - val_loss: 2.3049 - val_accuracy: 0.1081\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 20s 52ms/step - loss: 2.3057 - accuracy: 0.1074 - val_loss: 2.3046 - val_accuracy: 0.1060\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 21s 56ms/step - loss: 2.3056 - accuracy: 0.1076 - val_loss: 2.3089 - val_accuracy: 0.1060\n",
            "313/313 [==============================] - 4s 9ms/step - loss: 2.3055 - accuracy: 0.1135\n",
            "VGG16 on MNIST - Test accuracy: 0.11349999904632568\n",
            "313/313 [==============================] - 2s 7ms/step\n",
            "Epoch 1/10\n",
            "375/375 [==============================] - 63s 76ms/step - loss: 2.3751 - accuracy: 0.1891 - val_loss: 2.3597 - val_accuracy: 0.1035\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 27s 71ms/step - loss: 2.0505 - accuracy: 0.3269 - val_loss: 2.2652 - val_accuracy: 0.1576\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 25s 67ms/step - loss: 2.0598 - accuracy: 0.3116 - val_loss: 7.6413 - val_accuracy: 0.2874\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 27s 71ms/step - loss: 1.9335 - accuracy: 0.3505 - val_loss: 1.9480 - val_accuracy: 0.3483\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 27s 72ms/step - loss: 1.8153 - accuracy: 0.3758 - val_loss: 4.6154 - val_accuracy: 0.3311\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 26s 68ms/step - loss: 1.8055 - accuracy: 0.3831 - val_loss: 1.7002 - val_accuracy: 0.3871\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 27s 71ms/step - loss: 1.7865 - accuracy: 0.3934 - val_loss: 3.7304 - val_accuracy: 0.3659\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 27s 71ms/step - loss: 1.8489 - accuracy: 0.3854 - val_loss: 3.7996 - val_accuracy: 0.3889\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 27s 71ms/step - loss: 1.7274 - accuracy: 0.4058 - val_loss: 1.8123 - val_accuracy: 0.4129\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 26s 71ms/step - loss: 1.7890 - accuracy: 0.3988 - val_loss: 6.5075 - val_accuracy: 0.4029\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 6.8833 - accuracy: 0.3957\n",
            "ResNet50 on MNIST - Test accuracy: 0.39570000767707825\n",
            "313/313 [==============================] - 4s 10ms/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "29084464/29084464 [==============================] - 2s 0us/step\n",
            "Epoch 1/10\n",
            "375/375 [==============================] - 100s 95ms/step - loss: 1.8975 - accuracy: 0.3299 - val_loss: 1.7982 - val_accuracy: 0.3645\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 33s 87ms/step - loss: 1.6856 - accuracy: 0.3991 - val_loss: 3.8988 - val_accuracy: 0.3199\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 33s 87ms/step - loss: 1.6478 - accuracy: 0.4082 - val_loss: 1.6440 - val_accuracy: 0.4075\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 33s 87ms/step - loss: 1.6100 - accuracy: 0.4198 - val_loss: 1.7115 - val_accuracy: 0.3910\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 32s 85ms/step - loss: 1.6238 - accuracy: 0.4195 - val_loss: 1.6625 - val_accuracy: 0.3992\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 30s 81ms/step - loss: 1.5901 - accuracy: 0.4256 - val_loss: 1.5893 - val_accuracy: 0.4260\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 31s 82ms/step - loss: 1.5961 - accuracy: 0.4268 - val_loss: 1.5977 - val_accuracy: 0.4195\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 32s 84ms/step - loss: 1.5823 - accuracy: 0.4297 - val_loss: 1.8705 - val_accuracy: 0.3459\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 33s 88ms/step - loss: 1.6372 - accuracy: 0.4169 - val_loss: 3.0343 - val_accuracy: 0.3288\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 31s 82ms/step - loss: 1.6197 - accuracy: 0.4209 - val_loss: 1.6328 - val_accuracy: 0.4121\n",
            "313/313 [==============================] - 7s 16ms/step - loss: 1.6360 - accuracy: 0.4092\n",
            "DenseNet121 on MNIST - Test accuracy: 0.4092000126838684\n",
            "313/313 [==============================] - 5s 11ms/step\n",
            "Epoch 1/10\n",
            "375/375 [==============================] - 4s 7ms/step - loss: 1.7791 - accuracy: 0.3568 - val_loss: 1.6047 - val_accuracy: 0.4117\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.5559 - accuracy: 0.4281 - val_loss: 1.5380 - val_accuracy: 0.4385\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 1.5093 - accuracy: 0.4460 - val_loss: 1.5213 - val_accuracy: 0.4336\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.4826 - accuracy: 0.4546 - val_loss: 1.5028 - val_accuracy: 0.4440\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.4655 - accuracy: 0.4574 - val_loss: 1.4944 - val_accuracy: 0.4474\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.4527 - accuracy: 0.4638 - val_loss: 1.4807 - val_accuracy: 0.4558\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.4396 - accuracy: 0.4677 - val_loss: 1.4741 - val_accuracy: 0.4561\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.4278 - accuracy: 0.4708 - val_loss: 1.4602 - val_accuracy: 0.4621\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.4178 - accuracy: 0.4744 - val_loss: 1.4618 - val_accuracy: 0.4545\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.4085 - accuracy: 0.4784 - val_loss: 1.4618 - val_accuracy: 0.4565\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.4553 - accuracy: 0.4558\n",
            "LeNet on Fashion MNIST - Test accuracy: 0.45579999685287476\n",
            "313/313 [==============================] - 1s 3ms/step\n",
            "Epoch 1/10\n",
            "375/375 [==============================] - 26s 60ms/step - loss: 1.8517 - accuracy: 0.3066 - val_loss: 1.6225 - val_accuracy: 0.4014\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 1.5762 - accuracy: 0.4135 - val_loss: 1.6110 - val_accuracy: 0.4027\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 20s 54ms/step - loss: 1.5224 - accuracy: 0.4362 - val_loss: 1.5603 - val_accuracy: 0.4168\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 21s 57ms/step - loss: 1.4891 - accuracy: 0.4489 - val_loss: 1.5182 - val_accuracy: 0.4370\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 20s 55ms/step - loss: 1.4629 - accuracy: 0.4587 - val_loss: 1.5061 - val_accuracy: 0.4414\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 1.4445 - accuracy: 0.4648 - val_loss: 1.4861 - val_accuracy: 0.4482\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 22s 59ms/step - loss: 1.4215 - accuracy: 0.4737 - val_loss: 1.4938 - val_accuracy: 0.4508\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 1.4029 - accuracy: 0.4794 - val_loss: 1.4934 - val_accuracy: 0.4476\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 21s 57ms/step - loss: 1.3860 - accuracy: 0.4850 - val_loss: 1.4941 - val_accuracy: 0.4599\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 21s 55ms/step - loss: 1.3692 - accuracy: 0.4906 - val_loss: 1.5084 - val_accuracy: 0.4413\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.4989 - accuracy: 0.4476\n",
            "VGG16 on Fashion MNIST - Test accuracy: 0.44760000705718994\n",
            "313/313 [==============================] - 2s 6ms/step\n",
            "Epoch 1/10\n"
          ]
        }
      ]
    }
  ]
}
